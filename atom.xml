<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>taosean&#39;s 学习之旅</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://taosean.github.io/"/>
  <updated>2019-10-29T09:23:01.215Z</updated>
  <id>https://taosean.github.io/</id>
  
  <author>
    <name>taosean</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>打包 Python 工程</title>
    <link href="https://taosean.github.io/2019/10/29/Packaging-Python/"/>
    <id>https://taosean.github.io/2019/10/29/Packaging-Python/</id>
    <published>2019-10-29T09:00:59.000Z</published>
    <updated>2019-10-29T09:23:01.215Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要介绍了两个用来将 Python 工程的依赖进行打包以便于部署的 Python 库。</p><a id="more"></a><ol><li>PEX <a href="https://github.com/pantsbuild/pex" target="_blank" rel="noopener">github</a> <a href="https://pex.readthedocs.io/" target="_blank" rel="noopener">文档</a> <a href="https://medium.com/ovni/pex-python-executables-c0ea39cee7f1" target="_blank" rel="noopener">博客</a></li><li>shiv <a href="https://github.com/linkedin/shiv" target="_blank" rel="noopener">github</a> <a href="https://shiv.readthedocs.io/en/latest/" target="_blank" rel="noopener">文档</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍了两个用来将 Python 工程的依赖进行打包以便于部署的 Python 库。&lt;/p&gt;
    
    </summary>
    
    
      <category term="PEX" scheme="https://taosean.github.io/tags/PEX/"/>
    
      <category term="shiv" scheme="https://taosean.github.io/tags/shiv/"/>
    
      <category term="dependencies" scheme="https://taosean.github.io/tags/dependencies/"/>
    
      <category term="依赖" scheme="https://taosean.github.io/tags/%E4%BE%9D%E8%B5%96/"/>
    
      <category term="python" scheme="https://taosean.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>将 Tensorflow 模型移植到 Caffe 上</title>
    <link href="https://taosean.github.io/2019/10/22/Convert-Tensorflow-Model-to-Caffe/"/>
    <id>https://taosean.github.io/2019/10/22/Convert-Tensorflow-Model-to-Caffe/</id>
    <published>2019-10-22T07:32:49.000Z</published>
    <updated>2020-10-16T07:33:33.158Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要以 cosine metric learning 工程为例，记录了如何将一个 Tensorflow 模型 (包含 ckpt 文件) 移植到 Caffe 框架下。</p><a id="more"></a><h2 id="流程"><a class="markdownIt-Anchor" href="#流程"></a> 流程</h2><blockquote><ol><li>根据 Tensorflow 的网络定义源码，手动编写 Caffe 的网络定义文件 *.prototxt.</li><li>将训练好的 ckpt 文件中的参数 dump 到磁盘，存为 npy 文件。</li><li>使用 pycaffe API, 加载 prototxt 文件，生成 Net 对象。</li><li>根据 npy 文件与 Net 对象中网络层的对应关系，将 npy 文件中的值赋给 Net 对象中的参数。</li><li>将 Net 对象保存为 caffemodel 文件到磁盘。</li></ol></blockquote><br><h2 id="一些应该注意的点"><a class="markdownIt-Anchor" href="#一些应该注意的点"></a> 一些应该注意的点</h2><blockquote><p><strong>1</strong>. Tensorflow 中的 BN 层对应 Caffe 中的两个层，BatchNorm + Scale. 这是因为 Batch Normalization 算法最后有一个 缩放+偏置 的操作，这就对应 Caffe 中的 Scale 层。通常 Scale 层的缩放参数记为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span></span></span></span>, 偏置参数记为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span>. 有时候，从 ckpt 模型中 dump 出的 npy 文件没有 BN 层对应的 gamma 值，这可能是因为其在训练时没有使用缩放（batch_norm 函数的 scale 参数设为了 None ），也就是 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>γ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\gamma=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>。因此在流程第 4 步时，将相应 shape 的值全为 1 的 ndarray 赋给 Net 对象中 Scale 层对应的 gamma 即可，即 <code>net.params[conv1_scale][0].data[...] = np.ones(bn_beta)</code>. 此外，若 npy 文件中有 BN 层对应的 beta 值，则在 prototxt 文件中对应的 Scale 层应设置 <code>bias_term: true</code>，因为这里的 beta 值就是 bias term. <a href="https://blog.csdn.net/zziahgf/article/details/78843350" target="_blank" rel="noopener">参考1</a> <a href="https://www.cnblogs.com/LaplaceAkuir/p/7811383.html" target="_blank" rel="noopener">参考2</a></p></blockquote><hr><blockquote><p><strong>2</strong>. ckpt 中 dump 出的 npy 文件中可能没有某些 Convolution 层的 bias 权重。因此，在 prototxt 文件中，为此 Convolution 层设置 <code>bias_term: false</code>.</p></blockquote><hr><blockquote><p><strong>3</strong>. 在从 ckpt 中 dump 出来的参数里，有些可能名如 <code>*/Adam</code>, <code>*/Adam_1</code>，这个是因为模型使用了 Adam 优化器，这两个是对某个参数更新的时候使用的，如果只是在测试阶段进行前向推导，则不需要这两个参数。<a href="https://www.jianshu.com/p/75d8df8511bc" target="_blank" rel="noopener">参考</a><br>但是如果是需要对模型进行 Finetune, 出现大量 Adam 变量丢失的错误，则有可能是 <strong>要恢复的变量的位置</strong> 和 <strong>Adam 优化器的位置</strong> 出错造成的。<a href="https://blog.csdn.net/shwan_ma/article/details/82868751" target="_blank" rel="noopener">【tensorflow】加载pretrained model出现的大量adam变量丢失</a></p></blockquote><hr><blockquote><p><strong>4</strong>. 一些 Tensorflow 的项目使用 <code>tf.image.decode_jpeg()</code> 函数来读取 jpg 图像，要注意的是，如果直接使用此函数的默认 <code>dct_method</code> 的话，此函数读取到的值将会跟 <code>cv2.imread()</code> 读取的值不一致。这是因为 <code>tf.image.decode_jpeg()</code> 函数默认会为了解码速度而牺牲一些解码精度。如果想要获得跟 <code>cv2.imread()</code> 相同的结果的话，设置参数 <code>dct_method='INTEGER_ACCURATE'</code>。<a href="https://github.com/tensorflow/tensorflow/issues/24893#issuecomment-454911098" target="_blank" rel="noopener">参考1</a> <a href="https://stackoverflow.com/a/45520846/8149027" target="_blank" rel="noopener">参考2</a><br>此外，<code>tf.image.decode_jpeg()</code> 函数返回的图像是 <code>RGB</code> 通道的，<code>cv2.imread()</code> 是 <code>BGR</code> 通道。</p></blockquote><hr><blockquote><p><strong>5</strong>. <strong>Tensorflow 和 Caffe 在某些操作上的区别</strong><br>  <strong>5-1</strong>. <strong>Feature map 以及 卷积核 维度顺序的区别</strong><br>在 Tensorflow 中，feature map 的默认索引顺序是 <code>NHWC</code>, 卷积核是 <code>HWIO</code>，而 Caffe 中两者的索引顺序是 <code>NCHW</code> 和 <code>OIHW</code>.<br>需要说明的是，如果输入是完全一样的图片，在将图像以及卷积核按各自索引顺序 transpose 好后，后续生成的 feature map 在理论上来说应是完全一样的，它们只是索引的顺序不一样而已(feature map 内部各元素之间的相对顺序是一致的)。<br>  <strong>5-2</strong>.** Flatten 操作的区别**<br>据上文所述，同样的输入以及卷积核在不同框架中计算得到的 feature map 是一致的。但是如果要对 feature map (4D) 进行 flatten 操作的话，则此结论可能不成立。因为 flatten 是将 3D 的 feature map 拉伸成 1D, 那么不同的顺序可能就会产生不同的 1D 向量 (内部元素的相对位置可能发生了改变).<br>对同一个 feature map, 若其 shape 为 <code>NHWC</code> （这里的 NHWC 与上文所说的 NHWC 意义不一样，针对某个特定的 feature map, 其 NHWC 的值是固定的）, Tensorflow 的顺序是沿着 <code>C -&gt; W -&gt; H</code>，而 Caffe 的顺序是沿着 <code>W -&gt; H -&gt; C</code>。两者 flatten 的顺序在其各自的输入 feature map 索引顺序中都是 <code>3 -&gt; 2 -&gt; 1</code><br>例如，一个 <code>1x3x3x2</code> 的 feature map.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">data =  [[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],   | H</span><br><span class="line">          [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],   |</span><br><span class="line">          [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]],  |</span><br><span class="line">      W  -------------</span><br><span class="line">         [[<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>],</span><br><span class="line">          [<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>],</span><br><span class="line">          [<span class="number">16</span>,<span class="number">17</span>,<span class="number">18</span>]]]</span><br><span class="line"></span><br><span class="line">Tensorflow: [<span class="number">1</span>, <span class="number">10</span>, <span class="number">2</span>, <span class="number">11</span>, <span class="number">3</span>, <span class="number">12</span>, <span class="number">4</span>, <span class="number">13</span>, ... ]</span><br><span class="line">Caffe: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, ...]</span><br></pre></td></tr></table></figure><blockquote><p>由于 两者 flatten 的顺序在其各自的输入 feature map 索引顺序中都是 <code>3 -&gt; 2 -&gt; 1</code>，因此若这两个 flatten 的输入是一样的话，则它们的输出也是一样的。由于 Caffe 中没有类似 Transpose 这样的层，因此我采取使用 pycaffe 将前向 inference 后 Flatten 层的输入取出，用 numpy 进行 transpose 后，再重新赋给 Flatten 层当输入，然后再次调用 pycaffe 的接口 <code>net.forward(start='', end='')</code> 指定从某个层开始前向传播，这里就指定 start 参数为 Flatten 层的 name. 这样，即可在 Caffe 中得到与 Tensorflow 中同样的 Flatten 层输出。<a href="https://github.com/BVLC/caffe/issues/2725#issue-93930312" target="_blank" rel="noopener">net.forward 指定起点</a><br>Caffe 的 Flatten 层有 <code>axis</code>, <code>end_axis</code> 两个参数，但是我无论如何设置都无法在不对输入进行 transpose 的情况下得到与 Tensorflow 一样的结果。也许是我没理解对这两个参数的意义。<a href="https://caffe.berkeleyvision.org/tutorial/layers/flatten.html" target="_blank" rel="noopener">参考1</a> <a href="https://stackoverflow.com/a/40401460/8149027" target="_blank" rel="noopener">参考2</a></p></blockquote><blockquote><p>  <strong>5-3</strong>.** Padding 操作的区别**<br>Caffe 中的所有 padding 操作都是对称的，也就是说如果设置 <code>pad_w=1</code> 则会在 feature map 的左右两边都 pad 一个像素。但是 Tensorflow 不是如此，有可能出现左边 pad 1, 右边 pad 2，或者上边 pad 1,下边 pad 2 的情况。因此，在移植时，要保持在 Tensorflow 和 Caffe 中的 padding 方式都一样，这样才能得到相同的结果。<br>下面讨论 Caffe 的 padding 与 Tensorflow 中 <code>SAME</code> padding 方式的差异。<br>正常情况下，如果 <code>kernel_size=3, stride=1</code> 那么 <code>SAME</code> padding 模式会保持输入输出的尺寸相同，因此，需要在输入的上下左右各 pad 1 个像素。这时，在 Caffe 里只要设置 <code>pad: 1</code> 就行，这样两者 pad 的结果就是一样的了。<br>但是，如果遇到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi mathvariant="normal">≠</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">stride\neq1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 的情况，情况就变得复杂。有可能两个框架某个 Convolution 或者 Pooling 操作的输入输出尺寸都一样，但是数值却不同。如下图所示 <a href="https://github.com/Microsoft/MMdnn/wiki/Error-in-mobilenet-conversion-from-Tensorflow-to-Caffe-Different-way-of-padding#the-reason-of-the-inconsistent-shapes-is-due-to-symmetric-padding-in-caffe" target="_blank" rel="noopener">来源</a><br><img src="padding_1.png" alt=""><br><img src="padding_2.png" alt=""><br>在 Tensorflow 中, <code>SAME</code> padding 模式的策略是: <a href="https://stackoverflow.com/a/53820765/8149027" target="_blank" rel="noopener">来源</a></p><blockquote><p>First, consider the <code>SAME</code> padding scheme. A detailed explanation of the reasoning behind it is given in these notes. Here, we summarize the mechanics of this padding scheme. When using ‘SAME’, the output height and width are computed as:</p></blockquote></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out_height = ceil(float(in_height) / float(strides[<span class="number">1</span>]))</span><br><span class="line">out_width  = ceil(float(in_width) / float(strides[<span class="number">2</span>]))</span><br></pre></td></tr></table></figure><blockquote><blockquote><p>The total padding applied along the height and width is computed as:</p></blockquote></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SAME padding 长度计算</span></span><br><span class="line"><span class="keyword">if</span> (in_height % strides[<span class="number">1</span>] == <span class="number">0</span>):</span><br><span class="line">  pad_along_height = max(filter_height - strides[<span class="number">1</span>], <span class="number">0</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  pad_along_height = max(filter_height - (in_height % strides[<span class="number">1</span>]), <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (in_width % strides[<span class="number">2</span>] == <span class="number">0</span>):</span><br><span class="line">  pad_along_width = max(filter_width - strides[<span class="number">2</span>], <span class="number">0</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  pad_along_width = max(filter_width - (in_width % strides[<span class="number">2</span>]), <span class="number">0</span>)</span><br></pre></td></tr></table></figure><blockquote><blockquote><p>Finally, the padding on the top, bottom, left and right are:</p></blockquote></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pad_top = pad_along_height // <span class="number">2</span></span><br><span class="line">pad_bottom = pad_along_height - pad_top</span><br><span class="line">pad_left = pad_along_width // <span class="number">2</span></span><br><span class="line">pad_right = pad_along_width - pad_left</span><br></pre></td></tr></table></figure><blockquote><blockquote><p>Note that the division by 2 means that there might be cases when the padding on both sides (top vs bottom, right vs left) are off by one. In this case, the bottom and right sides always get the one additional padded pixel. For example, when pad_along_height is 5, we pad 2 pixels at the top and 3 pixels at the bottom. Note that this is different from existing libraries such as cuDNN and Caffe, which explicitly specify the number of padded pixels and always pad the same number of pixels on both sides.</p></blockquote></blockquote><blockquote><blockquote><p>For the <code>VALID</code> scheme, the output height and width are computed as:</p></blockquote></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out_height = ceil(float(in_height - filter_height + <span class="number">1</span>) / float(strides[<span class="number">1</span>]))</span><br><span class="line">out_width  = ceil(float(in_width - filter_width + <span class="number">1</span>) / float(strides[<span class="number">2</span>]))</span><br></pre></td></tr></table></figure><blockquote><blockquote><p>and no padding is used.</p></blockquote></blockquote><blockquote><p>在我的实例中，由于最后进入 Flatten 层的 feature map 需要是 <code>13x13</code> 的，而输入图像此前一共经过了 3 次下采样，一次 MAX Pool, 两次 Convolution, 都是 <code>kernel_size=3, stride=2</code>。因此，如何使这三次操作的 padding 操作在两个框架中一致就成了关键问题。由于在 SAME padding 中，<br>                           <code>out_height = ceil(float(in_height) / float(strides[1])),</code><br>                           <code>out_width = ceil(float(in_width) / float(strides[2]))</code><br>因此，这三次下采样操作的输入尺寸存在这些可能性</p></blockquote><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">              13                      &lt;-  经过第二次 Conv, stride=2</span><br><span class="line">          /         \</span><br><span class="line">         /           \</span><br><span class="line">       25            26               &lt;-  经过第一次 Conv, stride=2</span><br><span class="line">    /     \       /     \</span><br><span class="line">   49     50     51      52           &lt;-   经过 MAX Pooling</span><br><span class="line">  /  \   /  \   /   \   /   \</span><br><span class="line">97   98 99 100 101 102 103 104        &lt;-      输入图像</span><br></pre></td></tr></table></figure></blockquote><blockquote><p>由于 Caffe 只能进行对称 padding，因此要选择一个合适的输入图像尺寸，使得在这三次操作时 Tensorflow 不会出现 padding 不对称的情况 (因为这在 Caffe 中无法实现)。<br>根据上段 <code>SAME padding 长度计算部分的公式</code>，我们要使得 <code>pad_along_width，pad_along_height</code> 的数值为 <strong>偶数</strong>，这样才能对称。因此，要使得 <strong><code>in_height % strides[1] != 0, in_width % strides[2] != 0</code></strong>。由于 <code>strides[1]=2</code>，因此，<code>in_height, in_width</code> 必须是 <strong>奇数</strong>。这样，就可以得到每次操作前的输入尺寸分别是 <code>97 -&gt; 49 -&gt; 25 -&gt; 13</code>。这样，在每次操作时，SAME padding 都会为 feature map 在空间维度上四周各 pad 一个像素。而在 Caffe 的对应层的定义里，只要设置 <code>pad: 1</code> 即可。</p></blockquote><hr><blockquote><p><strong>6</strong>. 关于 Tensorflow 中获取 Graph 中所有节点名称以及 ckpt 文件中的变量。<br>  <strong>6.1</strong>.<strong>读取 ckpt 中的变量</strong> <a href="https://www.jianshu.com/p/75d8df8511bc" target="_blank" rel="noopener">参考</a></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf;</span><br><span class="line"></span><br><span class="line"> reader = tf.train.NewCheckpointReader(<span class="string">"/path/to/model.ckpt"</span>)</span><br><span class="line"> variables = reader.get_variable_to_shape_map()</span><br><span class="line"> <span class="keyword">for</span> key <span class="keyword">in</span> variables:</span><br><span class="line">      w = reader.get_tensor(key)</span><br></pre></td></tr></table></figure><blockquote><p>  <strong>6.2</strong>. <strong>获取 Graph 中的所有结点名称，并计算得到某节点的值</strong> <a href="https://www.jianshu.com/p/3cee7ca5ebd8" target="_blank" rel="noopener">参考</a></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_op_names = [n.name <span class="keyword">for</span> n <span class="keyword">in</span> tf.get_default_graph().as_graph_def().node]</span><br><span class="line">conv1_op = tf.get_default_graph.get_tensor_by_name(<span class="string">'a_tensor_name_from_above_line:0'</span>)  <span class="comment"># 注意要在名称后面加 :0</span></span><br><span class="line">conv1_value = sess.run(conv1_op, feed_dict=&#123;...&#125;)</span><br></pre></td></tr></table></figure><br>### dump ckpt 中的参数以及生成 caffemodel 的两个脚本[dump ckpt](dump.py)[生成 caffemodel](tf2caffe.py)]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要以 cosine metric learning 工程为例，记录了如何将一个 Tensorflow 模型 (包含 ckpt 文件) 移植到 Caffe 框架下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Caffe" scheme="https://taosean.github.io/tags/Caffe/"/>
    
      <category term="Tensorflow" scheme="https://taosean.github.io/tags/Tensorflow/"/>
    
      <category term="Porting" scheme="https://taosean.github.io/tags/Porting/"/>
    
      <category term="移植" scheme="https://taosean.github.io/tags/%E7%A7%BB%E6%A4%8D/"/>
    
      <category term="padding" scheme="https://taosean.github.io/tags/padding/"/>
    
      <category term="flatten" scheme="https://taosean.github.io/tags/flatten/"/>
    
  </entry>
  
  <entry>
    <title>卡尔曼滤波</title>
    <link href="https://taosean.github.io/2019/07/04/Kalman-Filter/"/>
    <id>https://taosean.github.io/2019/07/04/Kalman-Filter/</id>
    <published>2019-07-04T05:29:47.000Z</published>
    <updated>2019-07-04T05:44:32.581Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要关注卡尔曼滤波的流程和 5 个公式。</p><a id="more"></a><p>卡尔曼滤波的主要思想：首先，根据时间步 <code>t-1</code> 的状态空间，通过状态转移矩阵和控制矩阵(控制量)，预测 <code>t</code> 时间步时的状态空间。由于 <code>t-1</code> 时间步的状态空间本身就不是准确的，含有噪声，且状态转移的过程也引入噪声，因此预测得到的 <code>t</code> 时间步的状态空间是不准确的。这时，我们在 <code>t</code> 时间步进行实际的测量，使用得到的测量结果去修正预测得到的状态空间。其实就是对预测的结果和测量的结果根据其不准确度(用协方差矩阵表示)来计算权重(即卡尔曼增益)，对两个结果进行加权平均，并依此得到 <code>t</code> 时间步最优的结果。</p><br>### 卡尔曼滤波的五个公式<center>![卡尔曼公式](format.jpg)<center><br>### 卡尔曼滤波模型<center>![卡尔曼滤波模型](Kalman_filter_model.png)<center></center></center></center></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要关注卡尔曼滤波的流程和 5 个公式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kalman" scheme="https://taosean.github.io/tags/Kalman/"/>
    
      <category term="tracking" scheme="https://taosean.github.io/tags/tracking/"/>
    
      <category term="卡尔曼" scheme="https://taosean.github.io/tags/%E5%8D%A1%E5%B0%94%E6%9B%BC/"/>
    
      <category term="卡尔曼滤波" scheme="https://taosean.github.io/tags/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/"/>
    
  </entry>
  
  <entry>
    <title>(转载) 浅谈多节点 CPU+GPU 协同计算负载均衡性设计</title>
    <link href="https://taosean.github.io/2019/06/26/Heterogeneous-Computing/"/>
    <id>https://taosean.github.io/2019/06/26/Heterogeneous-Computing/</id>
    <published>2019-06-26T07:34:27.000Z</published>
    <updated>2019-06-26T09:28:14.688Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自<a href="https://blog.csdn.net/zhang0311/article/details/8224093" target="_blank" rel="noopener">这里</a>，主要讲述了关于基于 CPU+GPU 的混合异构计算系统的内容。</p><a id="more"></a><p>近年来，基于 CPU+GPU 的混合异构计算系统开始逐渐成为国内外高性能计算领域的热点研究方向。在实际应用中，许多基于 CPU+GPU 的混合异构计算机系统表现出了良好的性能。但是，由于各种历史和现实原因的制约，异构计算仍然面临着诸多方面的问题，其中最突出的问题是程序开发困难，尤其是扩展到集群规模级别时这个问题更为突出。主要表现在扩展性、负载均衡、自适应性、通信、内存等方面。</p><h3 id="一-cpugpu协同计算模式"><a class="markdownIt-Anchor" href="#一-cpugpu协同计算模式"></a> 一、 CPU+GPU协同计算模式</h3><p>CPU+GPU异构协同计算集群如图1所示，CPU+GPU 异构集群可以划分成三个并行层次：节点间并行、节点内 CPU 与 GPU 异构并行、设备（CPU 或 GPU）内并行。根据这三个层次我们可以得到 CPU+GPU 异构协同计算模式为：<font color="orange">节点间分布式+节点内异构式+设备内共享式</font>。</p><p><strong>1 节点间分布式</strong><br>CPU+GPU 异构协同计算集群中，各个节点之间的连接与传统 CPU 集群一样，采用网络连接，因此，节点间采用了分布式的计算方式，可以采用 MPI 消息通信的并行编程语言。</p><p><strong>2 节点内异构式</strong><br>CPU+GPU 异构协同计算集群中，每个节点上包含多核 CPU 和一块或多块 GPU 卡，节点内采用了异构的架构，采用主从式的编程模型，即每个 GPU 卡需要由 CPU 进程/线程调用。</p><p>由于每个节点上，CPU 核数也比较多，计算能力也很大，因此，在多数情况下，CPU 也会参与部分并行计算，根据 CPU 是否参与并行计算，我们可以把 CPU+GPU 异构协同计算划分成两种计算模式：</p><p> 1) CPU/GPU 协同计算：CPU 只负责复杂逻辑和事务处理等串行计算，GPU 进行大规模并行计算；<br> 2) CPU+GPU 共同计算：由一个 CPU 进程/线程负责复杂逻辑和事务处理等串行计算，其它 CPU 进程/线程负责小部分并行计算，GPU 负责大部分并行计算。</p><p>由于 CPU/GPU 协同计算模式比 CPU+GPU 共同计算模式简单，下面的介绍中，我们以 CPU+GPU 共同计算模式为例进行展开介绍各种编程模式。</p><p>在 CPU+GPU 共同计算模式下，我们把所有的 CPU 统称为一个设备（device），如双路 8 核 CPU 共有 16 个核，我们把这 16 个核统称成一个设备；每个 GPU 卡成为一个设备。根据这种划分方式，我们可以采用 MPI 进程或 OpenMP 线程控制节点内的各设备之间的通信和数据划分。</p><p><strong>3 设备内共享式</strong><br> 1) CPU 设备：每个节点内的所有多核 CPU 采用了共享存储模型，因此，把节点内的所有多核 CPU 看作一个设备， 可以采用 MPI 进程或 OpenMP 线程、pThread 线程控制这些 CPU 核的并行计算。</p><p> 2) GPU 设备：GPU 设备内有自己独立的 DRAM 存储，GPU 设备也是共享存储模型，在 GPU 上采用 CUDA 或 OpenCL 编程控制 GPU 众核的并行计算。CUDA 编程模式只在 NVIDIA GPU 上支持，OpenCL 编程模式在 NVIDIA GP U和 AMD GPU 都支持。</p><p>根据前面对 CPU+GPU 异构协同计算模式的描述，我们可以得到 CPU+GPU 异构协同计算的编程模型（以 MPI 和 OpenMP 为例）如表1所示。</p><center>![图1 CPU+GPU异构协同计算架构](pic_1.jpg)<center><center>图1 CPU+GPU异构协同计算架构 <center><center>表1 CPU+GPU异构协同计算编程模型<center><center>![表1 CPU+GPU异构协同计算编程模型](pic_2.png)<center><h3 id="二-cpugpu协同计算负载均衡性设计"><a class="markdownIt-Anchor" href="#二-cpugpu协同计算负载均衡性设计"></a> 二、CPU+GPU协同计算负载均衡性设计</h3><p>下面以 模式2 为例简单介绍多节点 CPU+GPU 协同计算任务划分和负载均衡，模式2 的进程和线程与 CPU 核和 GPU 设备对应关系如 图2 所示。若采用主从式 MPI 通信机制，我们在节点 0 上多起一个进程（0号进程）作为主进程，控制其它所有进程。每个节点上启动3个计算进程，其中两个控制 GPU 设备，一个控制其余所有 CPU 核的并行，在 GPU 内采用 CUDA/OpenCL 并行，在 CPU 设备内采用 OpenMP 多线程并行。</p><p>由于 CPU+GPU 协同计算模式分为 3个层次，那么负载均衡性也需要在这 3个层次 上分别设计。在 模式2 的编程方式下，节点内和节点间均采用 MPI 进程，合二为一，设计负载均衡时，只需要做到进程间（设备之间）的负载均衡和 CPU 设备内 OpenMP 线程负载均衡、GPU 设备内 CUDA 线程负载均衡即可。</p><p>对于设备内，采用的是共享存储器模型，CPU 设备上的 OpenMP 线程可以采用 schedule(static / dynamic / guided )方式；GPU 设备上只要保证同一 warp 内的线程负载均衡即可。</p><p>对于 CPU+GPU 协同计算，由于 CPU 和 GPU 计算能力相差很大，因此，在对任务和数据划分时不能给 CPU 设备和 GPU 设备划分相同的任务/数据量，这就增加了 CPU 与 GPU 设备间负载均衡的难度。CPU 与 GPU 之间的负载均衡最好的方式是采用动态负载均衡的方法，然而有些应用无法用动态划分而只能采用静态划分的方式。下面我们分别介绍动态划分和静态划分。</p><p> 1) 动态划分：对于一些高性能计算应用程序，在 CPU 与 GPU 之间的负载均衡可以采用动态负载均衡的优化方法，例如有 N 个任务/数据，一个节点内有 2 个 GPU 卡，即三个设备（CPU 和 2个 GPU），动态负载均衡的方法是每个设备先获取一个任务/数据进行计算，计算之后立即获取下一个任务，不需要等待其他设备，直到 N 个任务/数据计算完成。这种方式只需要在集群上设定一个主进程，负责给各个计算进程分配任务/数据。</p><p> 2) 静态划分：在一些应用中，无法采用动态划分的方式，需要静态划分方法，然而静态划分方法使异构设备间的负载均衡变得困难，有时甚至无法实现。对于一些迭代应用程序，我们可以采用学习型的数据划分方法，如先让 CPU 和 GPU 分别做一次相同计算量的计算，然后通过各自的运行时间计算出 CPU 与 GPU 的计算能力比例，然后再对数据进行划分。</p><center>![图2 CPU+GPU协同计算示意图（以每个节点2个GPU为例）](pic_3.jpg)<center><center>图2 CPU+GPU协同计算示意图（以每个节点2个GPU为例<center><h3 id="三-cpugpu协同计算数据划分示例"><a class="markdownIt-Anchor" href="#三-cpugpu协同计算数据划分示例"></a> 三、CPU+GPU协同计算数据划分示例</h3><p>假设某一应用的数据特点如 图3 所示，从输出看，结果中的每个值的计算需要所有输入数据的信息，所有输出值的计算之间没有任何数据依赖性，可以表示成 outj=；从输入看，每个输入值对所有的输出值都产生影响，所有输入数据之间也没有任何数据依赖性。从数据特点可以看出，该应用既可以对输入进行并行数据划分也可以对输出进行数据划分。下面我们分析 CPU+GPU 协同计算时的数据划分方式。</p><center>![图3 并行数据示例](pic_4.jpg)<center><center>图3 并行数据示例<center><p><strong>1 按输入数据划分</strong></p><p>假设按输入数据划分，我们可以采用动态的方式给每个 CPU 或 GPU 设备分配数据，做到动态负载均衡，然而这种划分方式，使所有的线程向同一个输出位置保存结果，为了正确性，需要使所有的线程对每个结果进行原子操作，这样将会严重影响性能，极端情况下，所有线程还是按顺序执行的。因此，这种方式效果很差。</p><p><strong>2 按输出数据划分</strong></p><p>按输出数据划分的话可以让每个线程做不同位置的结果计算，计算完全独立，没有依赖性。如果采用静态划分的方式，由于 CPU 和 GPU 计算能力不同，因此，很难做到负载均衡。采用动态的方式可以做到负载均衡，即把结果每次给 CPU 或 GPU 设备一块，当设备计算完本次之后，立即向主进程申请下一个分块，这样可以做到完全负载均衡。按输出数据划分，无论采用静态划分还是动态划分，都会带来另外一个问题，由于每个结果的计算都需要所有输入信息，那么所有进程（设备）都需要读取一遍所有输入数据，动态划分时还不只一次，尤其对于输入数据很大时，这将会对输入数据的IO产生很大的影响，很有可能使 IO 程序性能瓶颈。</p><p><strong>3 按输入和输出同时划分</strong></p><p>由于按输入或按输出划分都存在不同的缺点，我们可以采用输入和输出同时划分的方式进行数据划分，如 图4 所示。</p><p>从输出角度，让所有的计算进程（设备）都有一份计算结果，设备内的线程对结果进行并行计算，每个设备都有一份局部的计算结果，所有设备都计算完毕之后，利用MPI进程对所有设备的计算结果进行规约，规约最后的结果即是最终的结果。</p><p>从输入角度，按输入数据动态划分给不同的计算进程（设备），这样可以满足所有的计算进程负载均衡。</p><center>![图4 CPU+GPU协同计算数据划分示例](pic_5.jpg)<center><center>图4 CPU+GPU协同计算数据划分示例<center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自&lt;a href=&quot;https://blog.csdn.net/zhang0311/article/details/8224093&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;，主要讲述了关于基于 CPU+GPU 的混合异构计算系统的内容。&lt;/p&gt;
    
    </summary>
    
    
      <category term="CPU" scheme="https://taosean.github.io/tags/CPU/"/>
    
      <category term="GPU" scheme="https://taosean.github.io/tags/GPU/"/>
    
      <category term="负载均衡" scheme="https://taosean.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
      <category term="异构" scheme="https://taosean.github.io/tags/%E5%BC%82%E6%9E%84/"/>
    
      <category term="协同计算" scheme="https://taosean.github.io/tags/%E5%8D%8F%E5%90%8C%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>一些 C++ 相关的概念和操作</title>
    <link href="https://taosean.github.io/2019/06/26/Cxx-Related/"/>
    <id>https://taosean.github.io/2019/06/26/Cxx-Related/</id>
    <published>2019-06-26T06:27:22.000Z</published>
    <updated>2019-06-26T08:25:09.415Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记录了一些常用的 C++ 相关的概念和操作。</p><a id="more"></a><br>##### string 与 char* 互转<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// string to char*</span></span><br><span class="line"><span class="built_in">string</span> name = <span class="string">"name"</span>;</span><br><span class="line"><span class="keyword">char</span> *str = (<span class="keyword">char</span>*)name.data();</span><br><span class="line"></span><br><span class="line"><span class="comment">// char* to string</span></span><br><span class="line"><span class="keyword">char</span> *name = <span class="string">"name"</span>;</span><br><span class="line"><span class="built_in">string</span> str = <span class="built_in">string</span>(name);</span><br></pre></td></tr></table></figure><br>##### 释放 std::vector 所占用的内存>在容器 vector 中，其内存占用的空间是只增不减的，比如说首先分配了 10,000 个字节，然后 erase 掉后面 9999个，则虽然有效元素只有一个，但是内存占用仍为 10,000 个。所有内存空间在 vector 析构时回收。一般，我们都会通过 vector 中成员函数 clear 进行一些清除操作，但它清除的是所有的元素，使 vector 的大小减少至 0，却不能减小 vector 占用的内存。要避免 vector 持有它不再需要的内存，这就需要一种方法来使得它从曾经的容量减少至它现在需要的容量，这样减少容量的方法被称为 “**收缩到合适（shrink to fit）**”。<p>使用以下代码可以实现此功能:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;T&gt;().swap(X)  <span class="comment">// X 的类型为 std::vector&lt;T&gt;;</span></span><br><span class="line"><span class="comment">//其相当于</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;T&gt;  temp(X);</span><br><span class="line">temp.swap(X);</span><br></pre></td></tr></table></figure><blockquote><p>其背后原理为:<strong><code>vector()</code> 使用 <code>vector</code> 的默认构造函数建立临时 <code>vector</code> 对象，再在该临时对象上调用 <code>swap</code> 成员，<code>swap</code> 调用之后对象 <code>X</code> 占用的空间就等于一个默认构造的对象的大小，临时对象就具有原来对象 <code>X</code> 的大小，而该临时对象随即就会被析构，从而其占用的空间也被释放。</strong></p></blockquote><p><a href="https://www.cnblogs.com/zhoug2020/p/4058487.html" target="_blank" rel="noopener">参考</a></p><br>#### 二维数组和双重指针在内存中的差别首先，下例是不可行的<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ROW 2</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> COL 3</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myputs</span><span class="params">(<span class="keyword">char</span> **pos)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> **p;</span><br><span class="line">    <span class="keyword">char</span> a[ROW][COL]=&#123;<span class="string">"abc"</span>, <span class="string">"def"</span>&#125;;</span><br><span class="line"></span><br><span class="line">    p = a;</span><br><span class="line">    myputs(p);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myputs</span><span class="params">(<span class="keyword">char</span> **p)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i, j;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; ROW; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; COL; j++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%c "</span>, p[i][j]); <span class="comment">// 试图用双重指针的方式访问二维数组，不可行</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>myputs(char **p)</code> 接受双重指针作为参数，<code>main()</code> 函数将二维数组的头指针赋给双重指针，并作为 <code>myputs(char **p)</code> 的参数传入，再使用 <code>p[i][j]</code> 的方式访问某个元素。这是不行的，而这与两者的内存分布有关。</p><hr><p><strong>二维数组的内存分布</strong></p><blockquote><p>定义了二维数组后，就会在内存中分配一块逻辑上连续的内存块。<code>char c[10][10]</code>，系统就会分配一块 100 字节的连续内存。也就是说这样的二维数组跟一维数组 <code>char c[100]</code> 具有相似的内存分布。<br>二维数组的内存分布如下：</p></blockquote><center>![二维数组的内存分布](2d_array.png)<center><p><strong>双重指针的内存分布</strong></p><blockquote><p>双重指针的内存分配一般采取动态方式</p></blockquote><center>![双重指针的内存分布](2d_pointer.png)<center><p>可以看出，当将二维数组的头指针赋值给双重指针后，再使用 <code>p[i][j]</code> 的方式访问里面的元素，就会出现错误。这是因为，二维数组的内存是以连续的方式分配的，但是在访问时，却使用了双重指针的方式进行访问，这就会导致段错误。</p><hr><p><strong>总结</strong></p><blockquote><p><code>char **p</code> 和 <code>char p[2][3]</code> 之间不能相互传递参数，因为它们具体的内存分布不一样，这样在运行时就会出现段错误。<br>此外还需注意的一点：<br>二维数组中的 <code>a[i][j]</code> 和双重指针中的 <code>a[i][j]</code> 的意思是不一样的。<br>二维数组 <code>int a[10][10]</code> 中，<code>a[i][j]</code> 指的是第 <code>i</code> 行第 <code>j</code> 列数元素。<br>双重指针中 <code>int **a</code> 中， <code>a[i][j]</code> 指的是第 <code>i</code> 个存放 <code>int *</code> 指针所指向地址中的第 <code>j</code> 个元素。也就是 <code>*(*(a+i)+j)</code>。</p></blockquote><p><a href="https://blog.csdn.net/u013684730/article/details/46565577" target="_blank" rel="noopener">原文</a></p></center></center></center></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记录了一些常用的 C++ 相关的概念和操作。&lt;/p&gt;
    
    </summary>
    
    
      <category term="C++" scheme="https://taosean.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>进程和线程及相关概念</title>
    <link href="https://taosean.github.io/2019/06/14/Process-and-Thread/"/>
    <id>https://taosean.github.io/2019/06/14/Process-and-Thread/</id>
    <published>2019-06-14T02:50:31.000Z</published>
    <updated>2019-10-29T09:22:28.378Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记录了进程，线程等相关内容。</p><a id="more"></a><blockquote><p>抛开各种技术细节，从应用程序角度讲：<br>1、在单核计算机里，有一个资源是无法被多个程序并行使用的：CPU。<br>没有操作系统的情况下，一个程序一直独占着全部 CPU。<br>如果要有两个任务来共享同一个 CPU，程序员就需要仔细地为程序安排好运行计划–某时刻 CPU 和由程序 A 来独享，下一时刻 CPU 由程序 B 来独享,而这种安排计划后来成为 OS 的核心组件，被单独名命为 “<strong>scheduler</strong>”，即“<strong>调度器</strong>”，它关心的只是怎样把单个 CPU 的运行拆分成一段一段的“运行片”，轮流分给不同的程序去使用，而在宏观上，因为分配切换的速度极快，就制造出多程序并行在一个 CPU 上的假象。</p></blockquote><blockquote><p>2、在单核计算机里，有一个资源可以被多个程序共用，然而会引出麻烦：<strong>内存</strong>。<br>在一个只有调度器，没有内存管理组件的操作系统上，程序员需要手工为每个程序安排运行的空间 – 程序A使用物理地址 <code>0x00-0xff</code>, 程序B使用物理地址<code>0x100-0x1ff</code>，等等。<br>然而这样做有个很大的问题：每个程序都要协调商量好怎样使用同一个内存上的不同空间，软件系统和硬件系统千差万别，使这种定制的方案没有可行性。<br>为了解决这个麻烦，计算机系统引入了“<strong>虚拟地址</strong>”的概念，从三方面入手来做：<br>2.1、硬件上，CPU 增加了一个专门的模块叫 MMU，负责转换虚拟地址和物理地址。<br>2.2、操作系统上，操作系统增加了另一个核心组件：<strong>memory management</strong>，即内存管理模块，它管理物理内存、虚拟内存相关的一系列事务。<br>2.3、应用程序上，发明了一个叫做【进程】的模型，（注意）每个进程都用【<strong>完全一样的</strong>】虚拟地址空间，然而经由操作系统和硬件MMU协作，映射到不同的物理地址空间上。不同的【进程】，都有各自独立的物理内存空间，不用一些特殊手段，是无法访问别的进程的物理内存的。</p></blockquote><blockquote><p>3、现在，不同的应用程序，可以不关心底层的物理内存分配，也不关心 CPU 的协调共享了。然而还有一个问题存在：有一些程序，想要共享 CPU，【并且还要共享同样的物理内存】，这时候，一个叫【线程】的模型就出现了，它们被包裹在进程里面，在调度器的管理下共享 CPU，拥有同样的虚拟地址空间，同时也共享同一个物理地址空间，然而，它们无法越过包裹自己的进程，去访问别一个进程的物理地址空间。</p></blockquote><blockquote><p>4、进程之间怎样共享同一个物理地址空间呢？不同的系统方法各异，符合 posix 规范的操作系统都提供了一个接口，叫 mmap，可以把一个物理地址空间映射到不同的进程中，由不同的进程来共享。</p></blockquote><blockquote><p>5、PS：在有的操作系统里，进程不是调度单位（即不能被调度器使用），线程是最基本的调度单位，调度器只调度线程，不调度进程，比如 VxWorks<br><a href="http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html#comment-270980" target="_blank" rel="noopener">来源</a></p></blockquote><br>>CPU+RAM+各种资源（比如显卡，光驱，键盘，GPS, 等等外设）构成我们的电脑，但是电脑的运行，实际就是 CPU 和相关寄存器以及 RAM 之间的事情。**一个最最基础的事实**：CPU 太快，太快，太快了，寄存器仅仅能够追的上他的脚步，RAM 和别的挂在各总线上的设备完全是望其项背。那当多个任务要执行的时候怎么办呢？轮流着来?或者谁优先级高谁来？不管怎么样的策略，一句话就是在 CPU 看来就是轮流着来。**一个必须知道的事实**：执行一段程序代码，实现一个功能的过程介绍 ，当得到 CPU 的时候，相关的资源必须也已经就位，就是显卡啊，GPS 啊什么的必须就位，然后 CPU 开始执行。这里除了 CPU 以外所有的就构成了这个程序的执行环境，也就是我们所定义的程序上下文。当这个程序执行完了，或者分配给他的 CPU 执行时间用完了，那它就要被切换出去，等待下一次 CPU 的临幸。在被切换出去的最后一步工作就是保存程序上下文，因为这个是下次他被 CPU 临幸的运行环境，必须保存。**串联起来的事实**：前面讲过在 CPU 看来所有的任务都是一个一个的轮流执行的，具体的轮流方法就是：先加载程序A的上下文，然后开始执行 A，保存程序 A 的上下文，调入下一个要执行的程序 B 的程序上下文，然后开始执行 B,保存程序 B 的上下文。。。。========= 重要的东西出现了========进程和线程就是这样的背景出来的，**两个名词不过是对应的CPU时间段的描述，名词就是这样的功能**。进程就是包换上下文切换的程序执行时间总和 = CPU 加载上下文 + CPU 执行 + CPU 保存上下文**线程是什么呢？**进程的颗粒度太大，每次都要有上下的调入，保存，调出。如果我们把进程比喻为一个运行在电脑上的软件，那么一个软件的执行不可能是一条逻辑执行的，必定有多个分支和多个程序段，就好比要实现程序 A，实际分成 a，b，c 等多个块组合而成。那么这里具体的执行就可能变成：程序 A 得到 CPU => CPU 加载上下文，开始执行程序 A 的 a 小段，然后执行 A 的 b 小段，然后再执行 A 的 c 小段，最后 CPU 保存  A 的上下文。这里 a，b，c 的执行是共享了 A 的上下文，CPU 在执行的时候没有进行上下文切换的。这里的 a，b，c 就是线程，也就是说线程是共享了进程的上下文环境的更为细小的 CPU 时间段。到此全文结束，再一个总结：**进程和线程都是一个时间段的描述，是 CPU 工作时间段的描述，不过是颗粒大小不同。**[来源](https://www.zhihu.com/question/25532384/answer/81152571)<br>>一、 cpu个数、核数、线程数的关系cpu个数：是指物理上，也及硬件上的核心数；核数：是逻辑上的，简单理解为逻辑上模拟出的核心数；线程数：是同一时刻设备能并行执行的程序个数，线程数=cpu个数 * 核数【如果有超线程，再乘以超线程数】<blockquote><p>二、 cpu线程数和Java多线程<br>首先明白几个概念：<br>(1) 单个cpu线程在同一时刻只能执行单一Java程序，也就是一个线程<br>(2) 单个线程同时只能在单个cpu线程中执行<br>(3) 线程是操作系统最小的调度单位，进程是资源（比如：内存）分配的最小单位<br>(4)Java中的所有线程在JVM进程中,CPU调度的是进程中的线程<br>(5)Java多线程并不是由于cpu线程数为多个才称为多线程，当Java线程数大于cpu线程数，操作系统使用时间片机制，采用线程调度算法，频繁的进行线程切换。</p></blockquote><blockquote><p>a 那么java多进程，每个进程又多线程，cpu是如何调度的呢？<br>个人理解：操作系统并不是单纯均匀的分配cpu执行不同的进程，因为线程是调度的最小单位，所以会根据不同进程中的线程个数进行时间分片，均匀的执行每个线程，也就是说A进程中有10个线程，而B进程中有2个线程，那么cpu分给进程的执行时间理论上应该是5:1才合理。</p></blockquote><blockquote><p>b cpu线程数和java线程数有直接关系吗？<br>个人理解：没有直接关系，正如上面所说，cpu采用分片机制执行线程，给每个线程划分很小的时间颗粒去执行，但是真正的项目中，一个程序要做很多的的操作，读写磁盘、数据逻辑处理、出于业务需求必要的休眠等等操作，当程序在进行I/O操作的时候，线程是阻塞的，线程由运行状态切换到等待状态，此时cpu会做上下文切换，以便处理其他的程序；当I/O操作完成后，cpu 会收到一个来自硬盘的中断信号，并进入中断处理例程，手头正在执行的线程因此被打断，回到 ready 队列。而先前因 I/O 而waiting 的线程随着 I/O 的完成也再次回到 就绪 队列，这时 cpu 可能会选择它来执行。</p></blockquote><blockquote><p>c 如何确定程序线程数？<br>个人理解：如果所有的任务都是计算密集型的，则创建的多线程数 = 处理器核心数就可以了<br>如果io操作比较耗时，则根据具体情况调整线程数，此时 多线程数 = n*处理器核心数<br>一般情况程序线程数等于cpu线程数的两到三倍就能很好的利用cpu了，过多的程序线程数不但不会提高性能，反而还会因为线程间的频繁切换而受影响，具体需要根据线程处理的业务考略，不断调整线程数个数，确定当前系统最优的线程数。<br><a href="https://blog.csdn.net/wutongyuWxc/article/details/78732287" target="_blank" rel="noopener">原文</a></p></blockquote><br>### 一篇非常好的文章>[进程与线程，单核与多核](https://cloud.tencent.com/developer/article/1352974)]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记录了进程，线程等相关内容。&lt;/p&gt;
    
    </summary>
    
    
      <category term="线程" scheme="https://taosean.github.io/tags/%E7%BA%BF%E7%A8%8B/"/>
    
      <category term="进程" scheme="https://taosean.github.io/tags/%E8%BF%9B%E7%A8%8B/"/>
    
      <category term="CPU" scheme="https://taosean.github.io/tags/CPU/"/>
    
      <category term="Process" scheme="https://taosean.github.io/tags/Process/"/>
    
      <category term="Thread" scheme="https://taosean.github.io/tags/Thread/"/>
    
      <category term="阻塞" scheme="https://taosean.github.io/tags/%E9%98%BB%E5%A1%9E/"/>
    
      <category term="非阻塞" scheme="https://taosean.github.io/tags/%E9%9D%9E%E9%98%BB%E5%A1%9E/"/>
    
      <category term="单核" scheme="https://taosean.github.io/tags/%E5%8D%95%E6%A0%B8/"/>
    
      <category term="多核" scheme="https://taosean.github.io/tags/%E5%A4%9A%E6%A0%B8/"/>
    
  </entry>
  
  <entry>
    <title>轻量卷积神经网络的一些操作</title>
    <link href="https://taosean.github.io/2019/06/03/light-weight-CNN-operations/"/>
    <id>https://taosean.github.io/2019/06/03/light-weight-CNN-operations/</id>
    <published>2019-06-03T09:33:04.000Z</published>
    <updated>2019-10-29T09:16:45.910Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记录一些在卷积神经网络轻量化的研究中出现的一些操作，其主要是针对卷积进行的。</p><a id="more"></a><h3 id="depthwise-convolution-and-pointwise-convolution"><a class="markdownIt-Anchor" href="#depthwise-convolution-and-pointwise-convolution"></a> Depthwise Convolution and Pointwise Convolution</h3><p><font color="orange">深度卷积</font> 分解一个标准的卷积为一个 depthwise convolution 和一个 pointwise convolution, 是对输入的每一个 channel 独立进行卷积，输入 feature map 的每个 channel 会输出 <strong>channel_multiplier</strong> (通常为 1) 个通道，最后的 feature map 就会有 in_channels * channel_multiplier 个通道了。</p><hr><center>![传统卷积和深度卷积以及逐点卷积的对比_1](convs.jpg)<center><hr><center>![传统卷积和深度卷积以及逐点卷积的对比_2](convs_2.jpg)<center><br>### Group Convolution and channel shuffle<center>![分组卷积](GConv.png)<center><p><font color="orange"><strong>Group Convolution</strong></font> 顾名思义，是对输入 feature map 进行分组，然后每组分别卷积。假设输入 feature map 的尺寸为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mi mathvariant="normal">∗</mi><mi>H</mi><mi mathvariant="normal">∗</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">C∗H∗W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord">∗</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord">∗</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span>，输出 feature map 的数量为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>，如果设定要分成 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span></span></span></span> 个 groups，则每组的输入 feature map 数量为 $$\frac{C}{G}$$，每组的输出 feature map 数量为 $$\frac{N}{G}$$，每个卷积核的尺寸为 $$\frac{C}{G}\times K\times K$$，卷积核的总数仍为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span> 个，每组的卷积核数量为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mi>N</mi><mi>G</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{N}{G}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">G</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，卷积核只与其同组的输入 map 进行卷积，卷积核的总参数量为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mo>×</mo><mfrac><mi>C</mi><mi>G</mi></mfrac><mo>×</mo><mi>K</mi><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">N\times \frac{C}{G}\times K\times K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">G</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span>，可见，总参数量减少为原来的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>1</mn><mi>G</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{G}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">G</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，其连接方式如上图右所示，group 1 的输出 map 数为 2，有 2 个卷积核，每个卷积核的 channel 数为 4，与 group1 的输入 map 的 channel 数相同，卷积核只与同组的输入 map 卷积，而不与其他组的输入 map 卷积。</p><p><font color="orange"><strong>Channel shuffle</strong></font>: 因为在<strong>同一组中不同的通道蕴含的信息可能是相同的</strong>，如果不进行通道交换的话，<strong>学出来的特征会非常局限</strong>。如果在不同的组之后交换一些通道，那么就能<strong>交换信息，使得各个组的信息更丰富</strong>，能提取到的特征自然就更多，这样是有利于得到更好的结果。</p><hr><center>![Channel Shuffle](channel_shuffle.jpg)<center><p>ShuffleNet主要拥有两个创新点：</p><blockquote><ol><li>pointwise group convolution <font color="orange"><strong>逐点组卷积，就是带分组的卷积核为1×1的卷积，也就是说逐点组卷积是卷积核为 1×1 的分组卷积</strong></font>。</li><li>channel shuffle</li></ol></blockquote><p>原因：</p><blockquote><ol><li>逐点卷积占了很大的计算量 ———&gt; 逐点分组卷积</li><li>不同组之间特征通信问题   ———&gt; channel shuffle</li></ol></blockquote><hr><p><font color="orange"><strong>GDC :</strong></font> 更进一步，如果分组数 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi><mo>=</mo><mi>N</mi><mo>=</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">G=N=C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>，同时卷积核的尺寸与输入 map 的尺寸相同，即 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi><mo>=</mo><mi>H</mi><mo>=</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">K=H=W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span>，则输出 map 为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mi mathvariant="normal">∗</mi><mn>1</mn><mi mathvariant="normal">∗</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">C∗1∗1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord">∗</span><span class="mord">1</span><span class="mord">∗</span><span class="mord">1</span></span></span></span> 即长度为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span> 的向量，此时称之为 <strong>Global Depthwise Convolution（GDC）</strong>，见 MobileFaceNet，可以看成是全局加权池化，与 Global Average Pooling（GAP） 的不同之处在于，GDC 给每个位置赋予了可学习的权重（对于已对齐的图像这很有效，比如人脸，中心位置和边界位置的权重自然应该不同），而 GAP 每个位置的权重相同，全局取个平均，如下图所示：</p><hr><center>![Global Depthwise Convolution](GDC.png)<center><br>### Squeeze-and-Excitation module<font color="orange">**SE module**</font> 通过学习的方式来自动获取到每个特征通道的重要程度，然后依照计算出来的重要程度去提升有用的特征并抑制对当前任务用处不大的特征。<center>![SE module](SE.jpg)<center><hr><blockquote><ol><li>首先做普通的卷积，得到了一个 output feature map，它的 shape 为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">[</mo><mi>C</mi><mi mathvariant="normal">，</mi><mi>H</mi><mi mathvariant="normal">，</mi><mi>W</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[C，H，W]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mclose">]</span></span></span></span>，根据论文观点，这个 feature map 的特征很混乱。为了获得重要性的评价指标，直接对这个 feature map 做一个 Global Average Pooling，然后我们就得到了长度为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span> 的向量。（这里还涉及到一个额外的东西，如果你了解卷积，你就会发现一旦某一特征经常被激活，那么 Global Average Pooling 计算出来的值会比较大，说明它对结果的影响也比较大，反之越小的值，对结果的影响就越小）</li><li>然后我们对这个向量加两个 FC 层，做非线性映射，这两个 FC 层的参数，也就是网络需要额外学习的参数。</li><li>最后输出的向量，我们可以看做特征的重要性程度，然后与 feature map 对应 channel 相乘就得到特征有序的 feature map 了。</li></ol></blockquote></center></center></center></center></center></center></center></center></center></center></center></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记录一些在卷积神经网络轻量化的研究中出现的一些操作，其主要是针对卷积进行的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="CNN" scheme="https://taosean.github.io/tags/CNN/"/>
    
      <category term="Convolution" scheme="https://taosean.github.io/tags/Convolution/"/>
    
      <category term="FLOPs" scheme="https://taosean.github.io/tags/FLOPs/"/>
    
      <category term="mobile" scheme="https://taosean.github.io/tags/mobile/"/>
    
      <category term="shuffle" scheme="https://taosean.github.io/tags/shuffle/"/>
    
      <category term="SE" scheme="https://taosean.github.io/tags/SE/"/>
    
  </entry>
  
  <entry>
    <title>Git的使用流程</title>
    <link href="https://taosean.github.io/2019/05/31/Git-Usage/"/>
    <id>https://taosean.github.io/2019/05/31/Git-Usage/</id>
    <published>2019-05-31T09:32:00.000Z</published>
    <updated>2019-06-20T05:03:40.701Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记录一些使用 Git 进行版本管理的流程和命令。</p><a id="more"></a><h2 id="概念建立"><a class="markdownIt-Anchor" href="#概念建立"></a> 概念建立</h2><p>1 工作区: 代码所在的文件路径<br>2 暂存区: 使用 <code>git add &lt;filename&gt;</code>，将文件 <filename> 添加进 暂存区，待后续操作。<br>3 本地仓库: 使用  <code>git commit -m &quot;comments here&quot;</code> 将 暂存区的所有文件 commit 到本地仓库，本地仓库位于本机。<br>4 远程仓库: 在服务器端运行，可将本地仓库内容通过 <code>git push</code> 推送到远程仓库。</filename></p><br>## 本地仓库和远程仓库的创建### 1. 添加远程库为了方便管理，创建 git 用户.在远程服务器上安装好 git 后，使用以下命令创建远程仓库<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir example.git</span><br><span class="line"><span class="built_in">cd</span> example.git</span><br><span class="line">git --bare init</span><br></pre></td></tr></table></figure><p>用 <code>chown -R git:git example.git</code> 将 <code>example.git</code> 的所有者和群组改为 git.</p><h3 id="2-添加本地仓库"><a class="markdownIt-Anchor" href="#2-添加本地仓库"></a> 2. 添加本地仓库</h3><p>若已经拥有了远程仓库，可以通过 <code>git clone &lt;example.git&gt;</code> 的命令将远程仓库 clone 到本地。<br>若是对已存在的工程添加 git 管理，则在工程目录下，使用 <code>git init</code> 命令将其变成 git 管理的仓库。</p><br>## 常用的 git 流程创建好本地仓库和远程仓库后，就可以使用 git 进行版本控制了。若是对已存在的工程进行操作，则流程如下:>1&emsp; 使用 git add <filename> 的方式将文件添加到暂存区。若某工程第一次使用 git，用 `git add .` 将工程目录下的所有文件添加到暂存区。此操作可以在 `Git bash` 中通过命令行操作，或者在 `Git GUI` 通过图形界面操作。<blockquote><hr><p>2  若已在暂存区中添加了一些文件，可以通过 <code>git commit -m &quot;comments here&quot;</code> 将暂存区中所有文件 commit 到本地仓库的当前分支。</p></blockquote><blockquote><hr><p>3  若要将本地的当前分支，如 master 分支推送到远程仓库的 master 分支，则使用 <code>git push</code> 命令。</p><blockquote><p>注意: 应先将本地仓库与远程仓库关联，在本地 <code>example</code> 工程下，使用语句 <code>git remote add origin git@10.167.93.74:/path/to/example.git</code>. 这样，就将 <code>10.167.93.74:/path/to/example.git</code> 与本地 <code>example</code> 仓库关联上了。添加后，远程库的名字就是 <code>origin</code>，这是 Git 默认的叫法，也可以改成别的，但是 <code>origin</code> 这个名字一看就知道是远程库。</p></blockquote></blockquote><blockquote><blockquote><hr><p>关联后，使用命令 <code>git push -u origin master</code> 第一次推送 <code>master</code> 分支的所有内容；</p></blockquote></blockquote><blockquote><blockquote><hr><p>此后，每次本地提交后，只要有必要，就可以使用命令 <code>git push origin master</code> 推送最新修改；</p></blockquote></blockquote><blockquote><p>注意: 若不想将工程路径下的所有文件添加版本管理，则可以只将部分文件进行 add, 对从未进行过 add 操作的文件，将被视作 <code>untracked</code>.</p></blockquote><blockquote><hr><p>4  若对已经被 Git 管理的多个文件在某次 commit 后进行了修改，想将这些文件一次性进行 add，可以使用命令 <code>git add -u</code>. 这样，就不会将那些 <code>untracked</code> 的文件添加进暂存区 (git 术语为进行 stage). 若使用 <code>git add .</code> 命令，将会提交 <strong>新文件</strong> (new) 和 <strong>被修改</strong> (modified) 文件，这时，那些 <code>untracked</code> 的文件会被看作 <code>新文件</code>。</p><blockquote><p><code>Git add</code> 命令的 3 种用法:</p></blockquote></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .  : 监控工作区的状态树，使用它会把工作时的所有变化提交到暂存区，包括文件内容修改 (modified) 以及新文件 (new)，但不包括被删除的文件。</span><br><span class="line">git add -u : 仅监控已经被 add 的文件（即 tracked file），他会将被修改的文件提交到暂存区。add -u 不会提交新文件（untracked file）。（git add --update 的缩写）</span><br><span class="line">git add -A : 上面两个功能的合集（git add --all 的缩写）</span><br></pre></td></tr></table></figure><blockquote><blockquote><p>示例</p></blockquote></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br><span class="line"><span class="built_in">echo</span> Change me &gt; change-me</span><br><span class="line"><span class="built_in">echo</span> Delete me &gt; delete-me</span><br><span class="line">git add change-me delete-me</span><br><span class="line">git commit -m initial</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> OK &gt;&gt; change-me</span><br><span class="line">rm delete-me</span><br><span class="line"><span class="built_in">echo</span> Add me &gt; add-me</span><br><span class="line"></span><br><span class="line">git status</span><br><span class="line"><span class="comment"># Changed but not updated:</span></span><br><span class="line"><span class="comment">#   modified:   change-me</span></span><br><span class="line"><span class="comment">#   deleted:    delete-me</span></span><br><span class="line"><span class="comment"># Untracked files:</span></span><br><span class="line"><span class="comment">#   add-me</span></span><br><span class="line"></span><br><span class="line">git add .</span><br><span class="line">git status</span><br><span class="line"></span><br><span class="line"><span class="comment"># Changes to be committed:</span></span><br><span class="line"><span class="comment">#   new file:   add-me</span></span><br><span class="line"><span class="comment">#   modified:   change-me</span></span><br><span class="line"><span class="comment"># Changed but not updated:</span></span><br><span class="line"><span class="comment">#   deleted:    delete-me</span></span><br><span class="line"></span><br><span class="line">git reset</span><br><span class="line"></span><br><span class="line">git add -u</span><br><span class="line">git status</span><br><span class="line"></span><br><span class="line"><span class="comment"># Changes to be committed:</span></span><br><span class="line"><span class="comment">#   modified:   change-me</span></span><br><span class="line"><span class="comment">#   deleted:    delete-me</span></span><br><span class="line"><span class="comment"># Untracked files:</span></span><br><span class="line"><span class="comment">#   add-me</span></span><br><span class="line"></span><br><span class="line">git reset</span><br><span class="line"></span><br><span class="line">git add -A</span><br><span class="line">git status</span><br><span class="line"></span><br><span class="line"><span class="comment"># Changes to be committed:</span></span><br><span class="line"><span class="comment">#   new file:   add-me</span></span><br><span class="line"><span class="comment">#   modified:   change-me</span></span><br><span class="line"><span class="comment">#   deleted:    delete-me</span></span><br></pre></td></tr></table></figure><blockquote><blockquote><p><a href="https://www.cnblogs.com/skura23/p/5859243.html" target="_blank" rel="noopener">参考</a></p></blockquote></blockquote><br>## 常用 Git 命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git add</span><br><span class="line">git commit</span><br><span class="line">git status</span><br><span class="line">git <span class="built_in">log</span></span><br><span class="line">git push &lt;remote&gt; &lt;<span class="built_in">local</span> branch name&gt;:&lt;remote branch to push into&gt;</span><br><span class="line">git <span class="built_in">log</span> --graph <span class="comment">#查看树状图</span></span><br></pre></td></tr></table></figure><br>## 常用 Git 工具· Git Bash· Git GUI· Pycharm 上的 Git<br>## 教程[Git教程-廖雪峰](https://www.liaoxuefeng.com/wiki/896043488029600)</filename>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记录一些使用 Git 进行版本管理的流程和命令。&lt;/p&gt;
    
    </summary>
    
    
      <category term="git" scheme="https://taosean.github.io/tags/git/"/>
    
      <category term="github" scheme="https://taosean.github.io/tags/github/"/>
    
      <category term="version control" scheme="https://taosean.github.io/tags/version-control/"/>
    
  </entry>
  
  <entry>
    <title>AlexeyAB/Darknet 的使用经验总结</title>
    <link href="https://taosean.github.io/2019/05/31/AlexyAB-Darknet/"/>
    <id>https://taosean.github.io/2019/05/31/AlexyAB-Darknet/</id>
    <published>2019-05-31T06:11:29.000Z</published>
    <updated>2019-07-04T05:47:40.516Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记录了 GitHub 上的热门 Repo <a href="https://github.com/AlexeyAB/darknet" target="_blank" rel="noopener">AlexeyAB/Darknet</a> 的一些使用要点。</p><a id="more"></a><h2 id="与-opencv-的速度比较"><a class="markdownIt-Anchor" href="#与-opencv-的速度比较"></a> 与 OpenCV 的速度比较</h2><blockquote><p> 使用 GPU 时此 Repo 速度比 OpenCV 快<br> 使用 CPU 时此 Repo 速度比 OpenCV 慢<br><a href="https://github.com/AlexeyAB/darknet/issues/3273#issuecomment-497096110" target="_blank" rel="noopener">来源</a></p></blockquote><br><h2 id="finetune-相关"><a class="markdownIt-Anchor" href="#finetune-相关"></a> Finetune 相关</h2><p>记在 base 数据集上训练得到的模型为 yolov3-old.weights, 当有新增数据集时，</p><blockquote><p> 若新增数据集和 base 数据<br>集类别一致，则在 yolov3-old.weights 的基础上，用 base+新增数据 进行训练。</p></blockquote><hr><blockquote><p> 若新增数据集包含其他类别，则先用 <code>darknet.exe partial cfg/yolov3.cfg yolov3.weights yolov3.conv.81 81</code> 得到 <code>yolov3.conv.81</code> 模型，再在此模型上用新数据集进行训练。<a href="https://github.com/AlexeyAB/darknet/issues/3264#issuecomment-496725772" target="_blank" rel="noopener">来源</a> <a href="https://github.com/AlexeyAB/darknet/blob/55dcd1bcb8d83f27c9118a9a4684ad73190e2ca3/build/darknet/x64/partial.cmd#L27" target="_blank" rel="noopener">partial命令</a></p></blockquote><br><h2 id="处理逻辑"><a class="markdownIt-Anchor" href="#处理逻辑"></a> 处理逻辑</h2><p>以使用单个 GPU 进行处理为例:</p><h3 id="font-size6训练font"><a class="markdownIt-Anchor" href="#font-size6训练font"></a> <font size="6">训练</font></h3><p>假设 cfg 文件中定义的 <code>batch=64</code>, <code>subdivisions=16</code></p><hr><blockquote><p>&lt;1&gt; 解析各种配置文件，如 <code>coco.data</code>, <code>coco.names</code> 等，获取各种参数。<br>&lt;2&gt; 解析 <code>cfg</code> 文件并将其实例化为 <code>network net</code> 对象. (注意，此过程中 net.batch 参数不是 cfg 文件中的 batch 值，而是 cfg 文件中 batch/subdivisions 得到的值。<code>net.batch</code> 的值为真正进行前向传播时的 batch size)<br>&lt;3&gt; 加载预训练模型 - <code>weights</code> 文件到 <code>net</code> 对象中。<br>&lt;4&gt; 获取所有训练图像的路径。<br>&lt;5&gt; 创建一个线程用来从磁盘中 load 数据，每次从磁盘中 load cfg 文件中的 batch 张图像到内存。<br>&lt;6&gt; 迭代训练。<br>  &lt;6.1&gt; 将一次从磁盘中读取的 batch (cfg 文件中) 张图像分成 <code>subdivisions</code> 份，即每份为 <code>net.batch</code>。使用 <code>net.batch</code> 张图像进行一次迭代，同时返回一个 <code>batch</code> 的 <code>loss</code>，最后，对 <code>subdivisions</code> 个 batch 的 loss 进行加和平均，得到一次从磁盘读取的所有图像 (cfg 中 batch 张) 的平均 loss.<br>  &lt;6.2&gt; 不断重复步骤 6.1，在某些迭代次数时生成模型以及计算 mAP.</p></blockquote><hr><h3 id="font-size6测试font"><a class="markdownIt-Anchor" href="#font-size6测试font"></a> <font size="6">测试</font></h3><p>由于 AlexeyAB 没有提供 批量测试 函数 (Batch Inference), 因此我自己实现了此功能。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// network.c 中添加以下函数</span></span><br><span class="line"><span class="function"><span class="keyword">float</span> **<span class="title">network_predict_image_batch_gpu</span><span class="params">(<span class="keyword">float</span> *imgBatch, network* net, <span class="keyword">float</span> thresh, <span class="keyword">float</span> hier_thresh, <span class="keyword">float</span> nms, metadata meta, <span class="keyword">int</span>* box_nums)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> w = network_width(net);</span><br><span class="line"><span class="keyword">int</span> h = network_height(net);</span><br><span class="line"><span class="keyword">int</span> batch = net-&gt;batch;</span><br><span class="line"><span class="keyword">int</span> c = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// predict batch images</span></span><br><span class="line">network_predict(*net, imgBatch);</span><br><span class="line"><span class="built_in">free</span>(imgBatch);</span><br><span class="line"></span><br><span class="line"><span class="keyword">float</span> **results = (<span class="keyword">float</span>**)<span class="built_in">calloc</span>(batch, <span class="keyword">sizeof</span>(<span class="keyword">float</span>*));</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; batch; i++) &#123;</span><br><span class="line"><span class="keyword">int</span> nboxes = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> letterbox = <span class="number">0</span>;</span><br><span class="line">detection * dets = get_network_boxes(net, w, h, thresh, hier_thresh, <span class="number">0</span>, <span class="number">1</span>, &amp;nboxes, letterbox);</span><br><span class="line">do_nms_sort(dets, nboxes, meta.classes, nms);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> real_box_num = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; nboxes; j++) &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> s = <span class="number">0</span>; s &lt; meta.classes; s++) &#123;</span><br><span class="line"><span class="keyword">if</span> (dets[j].prob[s] &gt; <span class="number">0</span>) &#123;</span><br><span class="line">real_box_num += <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">memcpy</span>(box_nums + i, &amp;real_box_num, <span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line"><span class="keyword">float</span> *res = (<span class="keyword">float</span>*)<span class="built_in">calloc</span>(real_box_num * <span class="number">6</span>, <span class="keyword">sizeof</span>(<span class="keyword">float</span>)); <span class="comment">// 6 is &#123;x, y, w, h, prob, class&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; nboxes; j++) &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> s = <span class="number">0</span>; s &lt; meta.classes; s++) &#123;</span><br><span class="line"><span class="keyword">float</span> now_prob = dets[j].prob[s];</span><br><span class="line"><span class="keyword">if</span> (now_prob &gt; <span class="number">0</span>) &#123;</span><br><span class="line">box b = dets[j].bbox;</span><br><span class="line"><span class="keyword">char</span> * nameTag = meta.names[s];</span><br><span class="line"><span class="keyword">float</span> x_ctr = b.x;</span><br><span class="line"><span class="keyword">float</span> y_ctr = b.y;</span><br><span class="line"><span class="keyword">float</span> width = b.w;</span><br><span class="line"><span class="keyword">float</span> height = b.h;</span><br><span class="line"><span class="keyword">float</span> cls_idx = (<span class="keyword">float</span>)s;</span><br><span class="line"></span><br><span class="line"><span class="built_in">memcpy</span>(res, &amp;x_ctr, <span class="number">1</span> * <span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line">res += <span class="number">1</span>;</span><br><span class="line"><span class="built_in">memcpy</span>(res, &amp;y_ctr, <span class="number">1</span> * <span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line">res += <span class="number">1</span>;</span><br><span class="line"><span class="built_in">memcpy</span>(res, &amp;width, <span class="number">1</span> * <span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line">res += <span class="number">1</span>;</span><br><span class="line"><span class="built_in">memcpy</span>(res, &amp;height, <span class="number">1</span> * <span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line">res += <span class="number">1</span>;</span><br><span class="line"><span class="built_in">memcpy</span>(res, &amp;now_prob, <span class="number">1</span> * <span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line">res += <span class="number">1</span>;</span><br><span class="line"><span class="built_in">memcpy</span>(res, &amp;cls_idx, <span class="number">1</span> * <span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line">res += <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">res -= real_box_num * <span class="number">6</span>;</span><br><span class="line">results[i] = res;</span><br><span class="line"></span><br><span class="line">free_detections(dets, nboxes);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; net-&gt;n; k++) &#123;</span><br><span class="line">layer temp_layer = net-&gt;layers[k];</span><br><span class="line"><span class="keyword">if</span> (temp_layer.type == YOLO || temp_layer.type == REGION || temp_layer.type == DETECTION) &#123;</span><br><span class="line">net-&gt;layers[k].output = net-&gt;layers[k].output + net-&gt;layers[k].outputs;</span><br><span class="line"><span class="comment">//temp_layer.output = temp_layer.output + temp_layer.outputs; 原来的版本</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> results;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果要将 darknet 编译成 dll 供其他程序使用，则在 darknet.h 里 network_predict_image 附近 加上</span></span><br><span class="line">LIB_API float **network_predict_image_batch_gpu(float *imgBatch, network* net, float thresh, float hier_thresh, float nms, metadata meta, int* box_nums)；</span><br></pre></td></tr></table></figure><p>调用此函数的示例代码</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">char</span>* configPath = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/mlit_yolo/mlit_yolo/cfg/yolov3-mlit-SD.cfg"</span>;</span><br><span class="line"><span class="keyword">char</span>* weightPath = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/mlit_yolo/mlit_yolo/backup/yolov3-mlit-SD_50000.weights"</span>;</span><br><span class="line"><span class="keyword">char</span>* metaPath = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/mlit_yolo/mlit_yolo/cfg/mlit.data"</span>;</span><br><span class="line"><span class="built_in">string</span> result_dir = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/mlit_yolo/mlit_yolo/result/"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">char</span>* img_path_1 = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/mlit_yolo/mlit_yolo/test_images/test_1.jpg"</span>;</span><br><span class="line"><span class="keyword">char</span>* img_path_2 = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/mlit_yolo/mlit_yolo/test_images/test_2.jpg"</span>;</span><br><span class="line"><span class="keyword">char</span>* img_path_3 = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/mlit_yolo/mlit_yolo/test_images/test_3.jpg"</span>;</span><br><span class="line"><span class="keyword">char</span>* img_path_4 = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/mlit_yolo/mlit_yolo/test_images/test_4.jpg"</span>;</span><br><span class="line"><span class="keyword">char</span>* img_path_5 = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/mlit_yolo/mlit_yolo/test_images/test_5.jpg"</span>;</span><br><span class="line"><span class="keyword">char</span>* img_path_6 = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/mlit_yolo/mlit_yolo/test_images/test_6.jpg"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> batchSize = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">char</span> **img_paths = (<span class="keyword">char</span>**)<span class="built_in">calloc</span>(batchSize, <span class="keyword">sizeof</span>(<span class="keyword">char</span>*));</span><br><span class="line">img_paths[<span class="number">0</span>] = img_path_1;</span><br><span class="line">img_paths[<span class="number">1</span>] = img_path_2;</span><br><span class="line">img_paths[<span class="number">2</span>] = img_path_3;</span><br><span class="line">img_paths[<span class="number">3</span>] = img_path_4;</span><br><span class="line">img_paths[<span class="number">4</span>] = img_path_5;</span><br><span class="line">img_paths[<span class="number">5</span>] = img_path_6;</span><br><span class="line"></span><br><span class="line"><span class="keyword">float</span> conf_thresh = <span class="number">0.6</span>;</span><br><span class="line"><span class="keyword">float</span> hier_thresh = <span class="number">0.5</span>;</span><br><span class="line"><span class="keyword">float</span> nms = <span class="number">0.45</span>;</span><br><span class="line"></span><br><span class="line">cuda_set_device(<span class="number">0</span>);</span><br><span class="line">network* netMain = load_network_custom(configPath, weightPath, <span class="number">0</span>, batchSize);</span><br><span class="line">metadata metaMain = get_metadata(metaPath);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> input_w = network_width(netMain);</span><br><span class="line"><span class="keyword">int</span> input_h = network_height(netMain);</span><br><span class="line"><span class="keyword">int</span> c = <span class="number">3</span>;</span><br><span class="line"><span class="comment">//int num_calsses = metaMain.classes;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里得到的 batch 就是上面手动设置的 batchSize</span></span><br><span class="line"><span class="keyword">int</span> batch = netMain-&gt;batch;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从 char** 中读取图像数据，并合并成 float *</span></span><br><span class="line"><span class="keyword">float</span> *imgBatch = (<span class="keyword">float</span>*)<span class="built_in">calloc</span>(batch * input_w * input_h * c, <span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//No OpenCV</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; batch; i++) &#123;</span><br><span class="line">image dark_image = load_image_color(img_paths[i], <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">image resized = resize_image(dark_image, input_w, input_h);</span><br><span class="line"><span class="built_in">memcpy</span>(imgBatch + i*input_w*input_h*c, resized.data, input_w*input_h*c * <span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *box_num_batch = (<span class="keyword">int</span>*)<span class="built_in">calloc</span>(batch, <span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line"><span class="keyword">float</span> **results = network_predict_image_batch_gpu(imgBatch, netMain, conf_thresh, hier_thresh, nms, metaMain, box_num_batch);</span><br><span class="line"><span class="keyword">float</span> *res;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 解析 results</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; batch; i++) &#123;</span><br><span class="line">cv::Mat image2show = cv::imread(img_paths[i]);</span><br><span class="line"><span class="keyword">int</span> ori_w = image2show.cols;</span><br><span class="line"><span class="keyword">int</span> ori_h = image2show.rows;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> nbox = *(box_num_batch + i);</span><br><span class="line">res = results[i];</span><br><span class="line"></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span> &lt;&lt; nbox &lt;&lt; <span class="string">" boxes detected"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; nbox; j++) &#123;</span><br><span class="line"><span class="keyword">float</span> x_ctr = res[<span class="number">0</span> + <span class="number">6</span> * j];</span><br><span class="line"><span class="keyword">float</span> y_ctr = res[<span class="number">1</span> + <span class="number">6</span> * j];</span><br><span class="line"><span class="keyword">float</span> width = res[<span class="number">2</span> + <span class="number">6</span> * j];</span><br><span class="line"><span class="keyword">float</span> height = res[<span class="number">3</span> + <span class="number">6</span> * j];</span><br><span class="line"><span class="keyword">float</span> prob = res[<span class="number">4</span> + <span class="number">6</span> * j];</span><br><span class="line"><span class="keyword">float</span> cls_idx = res[<span class="number">5</span> + <span class="number">6</span> * j];</span><br><span class="line"><span class="keyword">char</span> * nameTag = metaMain.names[(<span class="keyword">int</span>)(cls_idx)];</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> w_on_ori = (<span class="keyword">int</span>)(width * ori_w);</span><br><span class="line"><span class="keyword">int</span> h_on_ori = (<span class="keyword">int</span>)(height * ori_h);</span><br><span class="line"><span class="keyword">int</span> lft = (<span class="keyword">int</span>)(x_ctr * ori_w - w_on_ori / <span class="number">2</span>);</span><br><span class="line"><span class="keyword">int</span> rgt = (<span class="keyword">int</span>)(x_ctr * ori_w + w_on_ori / <span class="number">2</span>);</span><br><span class="line"><span class="keyword">int</span> top = (<span class="keyword">int</span>)(y_ctr * ori_h - h_on_ori / <span class="number">2</span>);</span><br><span class="line"><span class="keyword">int</span> bot = (<span class="keyword">int</span>)(y_ctr * ori_h + h_on_ori / <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">cv::<span class="function">Point <span class="title">pt1</span><span class="params">(lft, top)</span></span>;</span><br><span class="line">cv::<span class="function">Point <span class="title">pt2</span><span class="params">(rgt, bot)</span></span>;</span><br><span class="line">cv::rectangle(image2show, pt1, pt2, Scalar(<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>);</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> text = <span class="built_in">std</span>::<span class="built_in">string</span>(nameTag) + <span class="string">" ["</span> + to_string(<span class="keyword">int</span>(round(prob * <span class="number">100</span>))) + <span class="string">"]"</span>;</span><br><span class="line">cv::putText(image2show, text, Point(pt1.x, pt1.y - <span class="number">5</span>), cv::FONT_HERSHEY_COMPLEX, <span class="number">0.5</span>, Scalar(<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"&gt;&gt;&gt; %d %d %d %d %f &lt;&lt;&lt; "</span>, (<span class="keyword">int</span>)(x_ctr * ori_w), (<span class="keyword">int</span>)(y_ctr * ori_h), (<span class="keyword">int</span>)(width * ori_w), (<span class="keyword">int</span>)(height * ori_h), prob);</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; nameTag &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cv::imshow(<span class="string">"detected"</span>, image2show);</span><br><span class="line">cv::waitKey(<span class="number">0</span>);</span><br><span class="line"><span class="comment">//free(res);</span></span><br><span class="line"><span class="comment">//free_detections(res, nbox);</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">free</span>(box_num_batch);</span><br><span class="line"><span class="built_in">free</span>(results);</span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="font-size6主存与显存font"><a class="markdownIt-Anchor" href="#font-size6主存与显存font"></a> <font size="6">主存与显存</font></h3><p>在此 repo 的实现中，数据是先从磁盘读取到主存中，然后在使用 GPU 进行训练前，将主存中的数据拷贝至显存对象中，然后使用 GPU 进行运算。<br>参考 <code>network_kernels.cu</code> 中的 <code>float *network_predict_gpu(network net, float *input)</code> 函数。</p><p>在 Traffic counter 项目中，将来可能使用 GPU 版本的解码器，此解码器解码后的图像数据是在显存中的。因此，设想在将来的处理中，将略过从主存往显存拷贝数据这一步骤，直接传递显存中的对象，并进行处理。具体实现时，可重点参考 <code>float *network_predict_gpu(network net, float *input)</code> 函数。</p><h4 id="confidence-threshold"><a class="markdownIt-Anchor" href="#confidence-threshold"></a> Confidence threshold</h4><h4 id="nms-threshold"><a class="markdownIt-Anchor" href="#nms-threshold"></a> NMS threshold</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记录了 GitHub 上的热门 Repo &lt;a href=&quot;https://github.com/AlexeyAB/darknet&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;AlexeyAB/Darknet&lt;/a&gt; 的一些使用要点。&lt;/p&gt;
    
    </summary>
    
    
      <category term="gpu" scheme="https://taosean.github.io/tags/gpu/"/>
    
      <category term="yolo" scheme="https://taosean.github.io/tags/yolo/"/>
    
      <category term="yolov3" scheme="https://taosean.github.io/tags/yolov3/"/>
    
      <category term="darknet" scheme="https://taosean.github.io/tags/darknet/"/>
    
      <category term="cpu" scheme="https://taosean.github.io/tags/cpu/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV 4.0.1 + CUDA 8.0 + Visual Studio 2015 + Win10</title>
    <link href="https://taosean.github.io/2019/05/20/Build-opencv-with-GPU/"/>
    <id>https://taosean.github.io/2019/05/20/Build-opencv-with-GPU/</id>
    <published>2019-05-20T06:19:41.000Z</published>
    <updated>2019-05-23T09:03:26.642Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记录了使用 CUDA 8.0，Visual Studio 2015，Win10 来编译 OpenCV 4.0.1 的步骤。</p><a id="more"></a><h2 id="安装流程"><a class="markdownIt-Anchor" href="#安装流程"></a> 安装流程</h2><blockquote><p>[1].   安装好 CUDA 8.0. 各种路径添加到环境变量。</p></blockquote><hr><blockquote><p>[2]. 下载 Opencv 源码到 <code>&lt;OpenCV_DIR&gt;</code> 及 对应版本的 opencv_contrib 到 <code>&lt;OpenCV_CONTRIB_DIR&gt;</code>.</p></blockquote><hr><blockquote><p>[3]. Cmake 生成 VS solution。<br>  3.1 打开 cmake. 在 <code>where is the source code</code> 中填入 <code>&lt;OpenCV_DIR&gt;</code>, 在 <code>Where to build the binaries</code> 中 填入 <code>&lt;OpenCV_DIR/build&gt;</code>。<br>  3.2 点击 configure, 选择 <code>Visual Studio 14 2015 Win64</code>. (一定要选带有 Win 64 字样的，否则会出错)<br>  3.3 点击 Finish。会进行 Configure。中途可能会跳出红色错误，这是由于下载 ffmpeg, ippicv, data, xfeatures2d 相关的文件失败造成的。报错信息里会提示查看 log 文件，打开 log 文件后，根据信息，手动到网址下去下载 dll, zip, cmake 等文件，下载好后，以 <code>&lt;MD码&gt;-&lt;name&gt;.&lt;ext&gt;</code> 的方式命名，放在 <code>&lt;OpenCV_DIR/.cache&gt;</code> 下的相关路径中。重新点击 configure.<br>  3.4 勾选中复选框 <code>BUILD_opencv_world</code>, <code>WITH_CUDA</code>, <code>OPENCV_ENABLE_NONFREE</code>. 将 <code>&lt;OpenCV_CONTRIB_DIR/modules&gt;</code> 路径添加到 <code>OPENCV_EXTRA_MODULES_PATH</code> 中，再次点击 Configure.<br>  3.5 勾选 <code>CUDA_FAST_MATH</code>, 点击 Configure. 屏幕上应该一片白，没有红色信息.<br>  3.5 点击 Generate 以生成 sln. 此过程不应报错。</p></blockquote><hr><blockquote><p>[4]. VS 编译 Opencv.sln<br>  4.1 <code>&lt;OpenCV_DIR/build&gt;</code> 下打开 OpenCV.sln, 点击 生成 -&gt; 配置管理器，选择 <code>Release</code>, <code>x64</code>.<br>  4.2 将 <code>color_detail.hpp</code> 的 <code>96-127</code> 行的 <strong><code>const</code></strong> 替换为 <strong><code>constexpr</code></strong>. 否则会出现 <code>error : dynamic initialization is not supported for a __constant__ variable</code> 的错误. <a href="https://github.com/opencv/opencv/issues/13491#issuecomment-450754826" target="_blank" rel="noopener">来源1</a>  <a href="https://answers.opencv.org/question/205673/building-opencv-with-cuda-win10-vs-2017/" target="_blank" rel="noopener">来源2</a><br>  4.3 生成 <code>ALL_BUILD</code>. (主要关注 opencv_world 工程，此工程生成成功即可，实际过程中出现了 opencv_perf_gapi 和 opencv_test_gapi 工程报错的问题，貌似对我们的项目没有影响。)<br>  4.4 成功生成 <code>ALL_BUILD</code> 后 (生成了 opencv_world401.lib 和 opencv_world401.dll)，右键 <code>INSTALL</code> -&gt; <code>仅用于项目</code> -&gt; <code>仅生成INSTALL</code>.<br>  4.5 在 <code>&lt;OpenCV_DIR/install&gt;</code> 下是最后得到的 lib, dll，头文件等。</p></blockquote><h2 id="参考文档"><a class="markdownIt-Anchor" href="#参考文档"></a> 参考文档</h2><p><a href="https://blog.csdn.net/Gordon_Wei/article/details/85775328" target="_blank" rel="noopener">【OpenCV】opencv4.0.1+opencv_contrib4.0.1+VS2015的编译</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记录了使用 CUDA 8.0，Visual Studio 2015，Win10 来编译 OpenCV 4.0.1 的步骤。&lt;/p&gt;
    
    </summary>
    
    
      <category term="opencv" scheme="https://taosean.github.io/tags/opencv/"/>
    
      <category term="vs" scheme="https://taosean.github.io/tags/vs/"/>
    
      <category term="cuda" scheme="https://taosean.github.io/tags/cuda/"/>
    
      <category term="gpu" scheme="https://taosean.github.io/tags/gpu/"/>
    
  </entry>
  
  <entry>
    <title>Pyinstaller with Scipy</title>
    <link href="https://taosean.github.io/2019/04/02/Pyinstaller-with-Scipy/"/>
    <id>https://taosean.github.io/2019/04/02/Pyinstaller-with-Scipy/</id>
    <published>2019-04-02T06:54:17.000Z</published>
    <updated>2019-04-02T11:27:33.560Z</updated>
    
    <content type="html"><![CDATA[<p>在将 python 工程用 pyinstaller 打包成 exe 时，由于 import 了 scipy 的一些功能，因此生成的 exe 一直报错，经过努力终于解决。</p><a id="more"></a><h2 id="问题来源"><a class="markdownIt-Anchor" href="#问题来源"></a> 问题来源</h2><p>在 MLIT 的项目中，有使用到 scipy 库中的一个函数。因此，有 <code>from scipy.spatial.distance import cdist</code> 这句，但是突然不知道哪里发生了改动 (推测是某些库的版本在安装其他库时发生了变化)，打包好的 exe 在执行上述 import 语句时总是报错。</p><h2 id="trail-and-error"><a class="markdownIt-Anchor" href="#trail-and-error"></a> Trail and Error</h2><p>1 | 由于 scipy 的版本在上次发版之后发生了改变（不知为啥），现在的版本为 1.2.0. 根据 <code>lib/site-packages/</code> 的痕迹推测之前的版本为 1.0.0. 但将 scipy 重装为 1.0.0 后仍然不成功。<br>2 | 按步骤 1 的方式操作后，<code>scipy/spatial/_spherical_voronoi.py</code> 中的 第 18 行 <code>from . import _voronoi</code> 仍然报错，大意为 <code>cannot import name _voronoi</code>. 其中，<code>_voronoi</code> 为 <code>scipy/spatial/</code>文件夹下的一个 pyd 文件，为 <code>_voronoi.pyd</code>. 可是事实上，我在 convert 的 bat 脚本中明明有通过 <code>hidden-import</code> 将此文件导入进去，生成的文件夹中也确实存在这个文件，但是程序总是无法成功导入。<br>3 | 后来经过搜索与分析，在 convert 脚本中添加了一行 <code>--paths=&quot;H:\Develop\Anaconda2\setup\Lib\site-packages\scipy\extra-dll&quot;</code>，就成功了。</p><h2 id="分析"><a class="markdownIt-Anchor" href="#分析"></a> 分析</h2><p>上述方法成功后，分析成功原因。在执行 convert 脚本时，有一系列跟 scipy 有关的 warning. 大致都是说 hidden-import 的 pyd 文件的依赖 dll 找不到，而这些 warning 在我印象中以前并未出现过。在添加了 <code>--paths=&quot;H:\Develop\Anaconda2\setup\Lib\site-packages\scipy\extra-dll</code> 这一参数后，不再有这些 warning, exe 也可以成功执行。</p><h2 id="资源"><a class="markdownIt-Anchor" href="#资源"></a> 资源</h2><p><a href="convert_server.bat">完整的 convert 脚本</a><br><a href="mlit_pkg_version_20190402.txt">python库版本</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在将 python 工程用 pyinstaller 打包成 exe 时，由于 import 了 scipy 的一些功能，因此生成的 exe 一直报错，经过努力终于解决。&lt;/p&gt;
    
    </summary>
    
    
      <category term="pyinstaller" scheme="https://taosean.github.io/tags/pyinstaller/"/>
    
      <category term="scipy" scheme="https://taosean.github.io/tags/scipy/"/>
    
  </entry>
  
  <entry>
    <title>光流法</title>
    <link href="https://taosean.github.io/2019/02/25/optical-flow/"/>
    <id>https://taosean.github.io/2019/02/25/optical-flow/</id>
    <published>2019-02-25T08:34:14.000Z</published>
    <updated>2019-06-03T09:23:53.191Z</updated>
    
    <content type="html"><![CDATA[<p>对光流法进行了一个大致的了解，并了解了在高速情况下通过图像金字塔进行光流计算的方法。</p><a id="more"></a><h2 id="光流的定义"><a class="markdownIt-Anchor" href="#光流的定义"></a> 光流的定义</h2><p><strong>光流</strong> 是空间运动物体在观察成像平面上的像素运动的瞬时速度，是利用图像序列中像素在时间域上的变化以及相邻帧之间的相关性来找到上一帧跟当前帧之间存在的对应关系，从而计算出相邻帧之间物体的运动信息的一种方法。一般而言，光流是由于场景中前景目标本身的移动、相机的运动，或者两者的共同运动所产生的。</p><h2 id="光流法的原理"><a class="markdownIt-Anchor" href="#光流法的原理"></a> 光流法的原理</h2><h3 id="光流法的基本假设"><a class="markdownIt-Anchor" href="#光流法的基本假设"></a> 光流法的基本假设</h3><ol><li><font color="orange">亮度恒定不变，</font>即同一目标在不同帧间运动时，其亮度不会发生改变。这是基本光流法的假定（所有光流法变种都必须满足），用于得到光流法基本方程</li><li><font color="orange">时间连续或运动是“小运动”，</font>即时间的变化不会引起目标位置的剧烈变化，相邻帧之间位移要比较小。同样也是光流法不可或缺的假定。</li></ol><h3 id="基本约束方程"><a class="markdownIt-Anchor" href="#基本约束方程"></a> 基本约束方程</h3><p>根据光流法的基本假设，可以推导得出光流法的基本约束方程。<br>  考虑一个三维的矩阵 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span>  其三个维度为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault">t</span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> 为图像的两个维度，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault">t</span></span></span></span> 为时间维度。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I(x,y,t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">t</span><span class="mclose">)</span></span></span></span> 表示 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault">t</span></span></span></span> 时刻的图像在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 坐标上的灰度值。<br>  根据两个基本假设，可得到方程</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>d</mi><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>+</mo><mi>d</mi><mi>y</mi><mo separator="true">,</mo><mi>t</mi><mo>+</mo><mi>d</mi><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I(x,y,t) = I(x+dx, y+dy, t+dt)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span><span class="mclose">)</span></span></span></span></span></p><p>由于是小运动，因此可对 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>d</mi><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>+</mo><mi>d</mi><mi>y</mi><mo separator="true">,</mo><mi>t</mi><mo>+</mo><mi>d</mi><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I(x+dx, y+dy, t+dt)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span><span class="mclose">)</span></span></span></span> 进行泰勒展开，即</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>d</mi><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>+</mo><mi>d</mi><mi>y</mi><mo separator="true">,</mo><mi>t</mi><mo>+</mo><mi>d</mi><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac><mi>d</mi><mi>x</mi><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow></mfrac><mi>d</mi><mi>y</mi><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>t</mi></mrow></mfrac><mi>d</mi><mi>t</mi><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">I(x+dx, y+dy, t+dt) = I(x,y,t) + \frac{\partial I}{\partial x}dx + \frac{\partial I}{\partial y}dy + \frac{\partial I}{\partial t}dt+\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.05744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault">x</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.25188em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.05744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">ϵ</span></span></span></span></span></p><p>结合上式，得到</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac><mi>d</mi><mi>x</mi><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow></mfrac><mi>d</mi><mi>y</mi><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>t</mi></mrow></mfrac><mi>d</mi><mi>t</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\frac{\partial I}{\partial x}dx + \frac{\partial I}{\partial y}dy + \frac{\partial I}{\partial t}dt=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.05744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault">x</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.25188em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.05744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span></span></p><p>令 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi><mo>=</mo><mfrac><mrow><mi>d</mi><mi>x</mi></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">u=\frac{dx}{dt}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">u</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">t</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi><mo>=</mo><mfrac><mrow><mi>d</mi><mi>y</mi></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">v=\frac{dy}{dt}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.277216em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322159999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">t</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, 得到</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac><mfrac><mrow><mi>d</mi><mi>x</mi></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow></mfrac><mfrac><mrow><mi>d</mi><mi>y</mi></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>t</mi></mrow></mfrac><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\frac{\partial I}{\partial x}\frac{dx}{dt} + \frac{\partial I}{\partial y}\frac{dy}{dt} + \frac{\partial I}{\partial t}=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.05744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault">x</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.25188em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714399999999998em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.05744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span></span></p><p>即</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>x</mi></msub><mi>u</mi><mo>+</mo><msub><mi>I</mi><mi>y</mi></msub><mi>v</mi><mo>=</mo><mo>−</mo><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_x u+I_y v=-I_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">u</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>这就是光流的基本约束方程。</p><h3 id="lucas-kanade-光流算法"><a class="markdownIt-Anchor" href="#lucas-kanade-光流算法"></a> Lucas-Kanade 光流算法</h3><p>  由于光流的基本约束方程 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>x</mi></msub><mi>u</mi><mo>+</mo><msub><mi>I</mi><mi>y</mi></msub><mi>v</mi><mo>=</mo><mo>−</mo><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_x u+I_y v=-I_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">u</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 只有一个约束，但是却有两个未知数，因此无法求解。为了能够求解出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(u,v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span>, 需要引入新的约束。<br>  Lucas-Kanade 光流算法引入了 <font color="orange"><strong>空间一致</strong></font> 假设，即所有的相邻像素有相似的行动。也即在目标像素周围 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">m\times m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">m</span></span></span></span> 的区域内，每个像素均拥有相同的光流矢量。以此假设解决式 $$I_x u+I_y v=-I_t$$ 无法求解的问题。</p><p><img src="LK.png" alt="LK光流法"><br>具体推导过程，参考 <a href="https://blog.csdn.net/sgfmby1994/article/details/68489944" target="_blank" rel="noopener">总结：光流–LK光流–基于金字塔分层的LK光流–中值流</a></p><br>## 基于金字塔分层的 LK 光流法&emsp;&emsp;根据光流的基本假设 2，光流适用于 **小运动** 场景，即相邻帧之间运动较小。因此，光流法无法直接处理运动较大的情况。因此，在处理运动较大的情况时，需要通过图像金字塔的方式。具体细节，同样参考 [总结：光流--LK光流--基于金字塔分层的LK光流--中值流](https://blog.csdn.net/sgfmby1994/article/details/68489944)<br>## 基于光流的运动目标检测（前景检测）算法![基于光流的运动目标检测（前景检测）算法流程图](fg.png)参考这篇文章 [计算机视觉--光流法(optical flow)简介](https://blog.csdn.net/qq_41368247/article/details/82562165)<br>## Reference[总结：光流--LK光流--基于金字塔分层的LK光流--中值流](https://blog.csdn.net/sgfmby1994/article/details/68489944)[计算机视觉--光流法(optical flow)简介](https://blog.csdn.net/qq_41368247/article/details/82562165)[【计算机视觉】光流法简单介绍](https://blog.csdn.net/jobbofhe/article/details/80448961)]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对光流法进行了一个大致的了解，并了解了在高速情况下通过图像金字塔进行光流计算的方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="目标检测" scheme="https://taosean.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="optical flow" scheme="https://taosean.github.io/tags/optical-flow/"/>
    
  </entry>
  
  <entry>
    <title>协方差及协方差矩阵</title>
    <link href="https://taosean.github.io/2019/01/25/covariance-and-covariance-matrix/"/>
    <id>https://taosean.github.io/2019/01/25/covariance-and-covariance-matrix/</id>
    <published>2019-01-25T02:49:16.000Z</published>
    <updated>2019-01-25T02:53:16.089Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要关注了协方差的定义、含义，协方差矩阵的性质以及 PCA 与协方差矩阵的关系</p><a id="more"></a><p>关于协方差的定义，这篇文章解释得很好<br><a href="https://blog.csdn.net/northeastsqure/article/details/50163031" target="_blank" rel="noopener">终于明白协方差的意义了</a></p><p>关于协方差矩阵的特征值特征向量和 PCA 的关系。这篇文章解释得很好。<br><a href="https://www.cnblogs.com/dengdan890730/p/5495078.html" target="_blank" rel="noopener">PCA算法是怎么跟协方差矩阵/特征值/特征向量勾搭起来的?</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要关注了协方差的定义、含义，协方差矩阵的性质以及 PCA 与协方差矩阵的关系&lt;/p&gt;
    
    </summary>
    
    
      <category term="协方差" scheme="https://taosean.github.io/tags/%E5%8D%8F%E6%96%B9%E5%B7%AE/"/>
    
      <category term="协方差矩阵" scheme="https://taosean.github.io/tags/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5/"/>
    
      <category term="PCA" scheme="https://taosean.github.io/tags/PCA/"/>
    
      <category term="主成分分析" scheme="https://taosean.github.io/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>Centos 系统下深度学习环境配置及 tensorflow 安装</title>
    <link href="https://taosean.github.io/2018/12/07/linux-install-setting-process/"/>
    <id>https://taosean.github.io/2018/12/07/linux-install-setting-process/</id>
    <published>2018-12-07T08:15:27.000Z</published>
    <updated>2019-03-05T12:49:31.821Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记录了在新安装完 Centos 系统后的 NVIDIA 显卡驱动、cuda、cudnn、以及 TensorFlow 等 python 库的安装及配置。</p><a id="more"></a><p>更改启动设置</p><blockquote><p>(1) 查看系统默认启动环境。<code>systemctl get-default</code> -&gt; <code>graphical.target</code><br>(2) 将默认启动环境设置为命令行。<code>systemctl set-default multi-user.target</code><br>(3) <code>reboot</code></p></blockquote><p>禁用系统自带的 nouveau 显卡驱动。</p><blockquote><p>(4) run the NVIDIA driver file, it will create two <code>.conf</code> file to disable the nouveau driver for you under <code>/etc/modeprobe.d</code> and <code>/usr/...</code></p></blockquote><p>重做内核镜像</p><blockquote><p>(5) <code>mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r)-nouveau.img</code>  # Backup image<br>(6) <code>dracut /boot/initramfs-$(uname -r).img $(uname -r)</code> # Create a new image<br>(7) <code>reboot</code></p></blockquote><p>安装 NVIDIA 显卡驱动</p><blockquote><p>(8) run the NVIDIA driver file again, finish the installation of NVIDIA driver.</p></blockquote><p>安装 Cuda</p><blockquote><p>(9) Install cuda 8.0, do not install the driver provided by cuda since we already installed the NVIDIA driver before.<br>(10) add <code>export PATH=/usr/local/cuda-8.0/bin:$PATH</code> and <code>export LD_LIBRARY_PATH=/usr/local/cuda-8/lib64:$LD_LIBRARY_PATH</code> to <code>~/.bashrc</code><br>(11) <code>source ~/.bashrc</code></p></blockquote><p>解压 cudnn</p><blockquote><p>(12) <code>tar zxvf cudnn.tgz</code> # extract cudnn files<br>copy extracted files to the corresponding folders under cuda installation directory</p></blockquote><p>安装 Anaconda/python</p><blockquote><p>(13) Install Ananconda. Do not add the Ananconda path to <code>/root/.bashrc</code>, add it to <code>~/.bashrc</code>.<br>(14) <code>source ~/.bashrc</code></p></blockquote><p>安装 tensorflow 或其他 python 库</p><blockquote><p>(15) <code>pip install tensorflow-gpu==1.0.0</code>. # Install GPU version tensorflow 1.0.0</p></blockquote><p>注意，安装 <code>1.0.0</code> 的 tensorflow 时，<code>numpy==1.16.2</code> 貌似会报错。因此，需要 check 一下 Anaconda 中 numpy 的版本。如果需要安装，则安装 <code>pip install numpy==1.14.2</code>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记录了在新安装完 Centos 系统后的 NVIDIA 显卡驱动、cuda、cudnn、以及 TensorFlow 等 python 库的安装及配置。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Windows 下利用共享内存实现进程间通信</title>
    <link href="https://taosean.github.io/2018/12/03/Inter-Process-Communication-by-Shared-Memory-on-Windows/"/>
    <id>https://taosean.github.io/2018/12/03/Inter-Process-Communication-by-Shared-Memory-on-Windows/</id>
    <published>2018-12-03T09:27:14.000Z</published>
    <updated>2018-12-06T08:30:16.835Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记载了在 Windows 下如何通过调用 WinApi ，利用 <code>共享内存</code> 实现 进程间通信 (Inter Process Communication, IPC).</p><a id="more"></a><p>   本文主要是通过 FileMapping 的方式实现进程间通信。目前已实现进程间共享字符串以及 opencv 的 Mat 对象 （以 <code>uchar *</code> 方式）。</p><br>## 两个 C++ 进程之间的通信参考文章 [C++共享内存实现（windows和linux）](https://blog.csdn.net/u012234115/article/details/82114631)<p>上面的文章只实现了字符串的进程间通信，根据实际需要，需要进程间传递图像对象，此处使用 opencv 的 <code>Mat</code> 对象来表示。由于 <code>Mat</code> 对象有一个 <code>uchar* data</code> 属性，指向 Mat 的实际数据。因此，这里通过传输 <code>uchar* data</code> 到共享内存，并在 Reader 中重建 <code>Mat</code> 对象 (C++)。<br>参考文章 <a href="https://www.cnblogs.com/Lalafengchui/p/4223584.html" target="_blank" rel="noopener">Windows进程间通信–共享内存映射文件（FileMapping）</a>.</p><p>**注意：**这里在传递时需要将图像的 长、宽、高 等参数一并传递，这样在 Reader 中可以根据读到的尺寸进行恢复。因为在 Reader 端一开始得到的是共享内存的首地址。C++ 中用三个 <code>int</code> 类型来表示 <code>width</code>, <code>height</code>, <code>channel</code>。这三个 <code>int</code> 是写到表示数据的 <code>uchar *</code> 的最前面的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// code snippet in img_reader.cpp</span></span><br><span class="line"><span class="keyword">int</span> width, height;</span><br><span class="line">uchar* tmp = (uchar*) <span class="built_in">malloc</span>(buffer_size);</span><br><span class="line"><span class="built_in">memcpy</span>(tmp, &amp;width, <span class="keyword">sizeof</span>(width)) <span class="comment">// 将 width 首地址开始的 4 个 byte 内容拷贝到 tmp 所指向的地址。</span></span><br><span class="line">tmp += <span class="keyword">sizeof</span>(width); <span class="comment">// tmp 向后移动 sizeof(width) 个 uchar 的长度。</span></span><br><span class="line"><span class="built_in">memcpy</span>(tmp, &amp;height, <span class="keyword">sizeof</span>(height))</span><br><span class="line">tmp += <span class="keyword">sizeof</span>(height)</span><br></pre></td></tr></table></figure><br>## C++ 和 python 进程之间的通信*C++ 作 Writer， python 作 Reader*参考文章：[Shared Memory Example (Python, ctypes, VC++)](https://mail.python.org/pipermail/python-list/2005-March/302108.html)。python 中 使用 `ctypes` 来调用 `win32 api`，方法与 C++ Reader 中的类似。区别在于获取共享内存的首地址后，python 中可以通过 slicing 的方式获取不同地址的值。最后得到 width, height, channel 以及数据，将数据转换成 ndarray 即可使用 opencv 显示。<br>## FileMapping 原理这里使用了 FileMapping 的方式进行 IPC。Writer 使用的 API 有>[CreateFile](https://docs.microsoft.com/en-us/windows/desktop/api/fileapi/nf-fileapi-createfilea)>[CreateFileMapping](https://docs.microsoft.com/en-us/windows/desktop/api/winbase/nf-winbase-createfilemappinga)>[MapViewOfFile](https://msdn.microsoft.com/en-us/library/windows/desktop/aa366761%28v=vs.85%29.aspx?f=255&MSPPError=-2147217396) `MapViewOfFile` 最后返回的是共享内存的指针。通过将数据 `memcpy` 到这里实现共享。<p>Reader 使用的 API 有</p><blockquote><p><a href="https://docs.microsoft.com/en-us/windows/desktop/api/winbase/nf-winbase-openfilemappinga" target="_blank" rel="noopener">OpenFileMapping</a><br><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366761%28v=vs.85%29.aspx?f=255&amp;MSPPError=-2147217396" target="_blank" rel="noopener">MapViewOfFile</a><br><code>MapViewOfFile</code> 最后返回的是共享内存的指针。可通过从这里读数据重建图像。</p></blockquote><p>关于以上提及 API 的详细解释：</p><blockquote><p><a href="https://blog.csdn.net/bxsec/article/details/76566011" target="_blank" rel="noopener">Windows核心编程-CreateFile详解</a></p></blockquote><br>## File Mapping 代码<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// img_writer.cpp</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;Windows.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;chrono&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2\core\core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2\highgui\highgui.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"></span><br><span class="line"><span class="comment">//struct MyData</span></span><br><span class="line"><span class="comment">//&#123;</span></span><br><span class="line"><span class="comment">//int width;</span></span><br><span class="line"><span class="comment">//int height;</span></span><br><span class="line"><span class="comment">//int channel;</span></span><br><span class="line"><span class="comment">//MyData(int _width, int _height, int _channel) : width(_width), height(_height), channel(_channel)</span></span><br><span class="line"><span class="comment">//&#123;&#125;</span></span><br><span class="line"><span class="comment">//&#125;;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">writeMemory</span><span class="params">(<span class="keyword">char</span>* imgDir)</span> </span>&#123;</span><br><span class="line"><span class="comment">// define shared data</span></span><br><span class="line"><span class="keyword">char</span> *shared_file_name = <span class="string">"file_name_sean"</span>;</span><br><span class="line"><span class="keyword">char</span> * shared_object_name = <span class="string">"Local\\object_name_sean"</span>;</span><br><span class="line"></span><br><span class="line">Mat img = imread(imgDir, IMREAD_COLOR);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> width = img.cols;</span><br><span class="line"><span class="keyword">int</span> height = img.rows;</span><br><span class="line"><span class="keyword">int</span> channel = img.channels();</span><br><span class="line">uchar* img_data = img.data;</span><br><span class="line"></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> data_size = <span class="keyword">sizeof</span>(uchar) * width * height * channel;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> buffer_size = data_size + <span class="number">3</span> * <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"share buffer "</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create shared memory file</span></span><br><span class="line">HANDLE hFile = CreateFile(shared_file_name,</span><br><span class="line">GENERIC_READ | GENERIC_WRITE,</span><br><span class="line">FILE_SHARE_READ | FILE_SHARE_WRITE,</span><br><span class="line"><span class="literal">NULL</span>,</span><br><span class="line">OPEN_ALWAYS, <span class="comment">// open exist or create new, overwrite file</span></span><br><span class="line">FILE_ATTRIBUTE_NORMAL,</span><br><span class="line"><span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (hFile == INVALID_HANDLE_VALUE)</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"create file error"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">HANDLE shared_file_handler = CreateFileMapping(</span><br><span class="line">hFile, <span class="comment">// Use paging file - shared memory</span></span><br><span class="line"><span class="literal">NULL</span>,                 <span class="comment">// Default security attributes</span></span><br><span class="line">PAGE_READWRITE,       <span class="comment">// Allow read and write access</span></span><br><span class="line"><span class="number">0</span>,                    <span class="comment">// High-order DWORD of file mapping max size</span></span><br><span class="line">buffer_size,            <span class="comment">// Low-order DWORD of file mapping max size</span></span><br><span class="line">shared_object_name);    <span class="comment">// Name of the file mapping object</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (shared_file_handler) &#123;</span><br><span class="line"><span class="comment">// map memory file view, get pointer to the shared memory</span></span><br><span class="line">LPVOID lp_base = MapViewOfFile(</span><br><span class="line">shared_file_handler,  <span class="comment">// Handle of the map object</span></span><br><span class="line">FILE_MAP_ALL_ACCESS,  <span class="comment">// Read and write access</span></span><br><span class="line"><span class="number">0</span>,                    <span class="comment">// High-order DWORD of the file offset</span></span><br><span class="line"><span class="number">0</span>,                    <span class="comment">// Low-order DWORD of the file offset</span></span><br><span class="line">buffer_size);           <span class="comment">// The number of bytes to map to view</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// write width, height, channel to a memory</span></span><br><span class="line">uchar* tmp = (uchar*) <span class="built_in">malloc</span>(buffer_size);</span><br><span class="line"><span class="built_in">memcpy</span>(tmp, &amp;width, <span class="keyword">sizeof</span>(width));</span><br><span class="line">tmp += <span class="keyword">sizeof</span>(width);</span><br><span class="line"><span class="built_in">memcpy</span>(tmp, &amp;height, <span class="keyword">sizeof</span>(height));</span><br><span class="line">tmp += <span class="keyword">sizeof</span>(height);</span><br><span class="line"><span class="built_in">memcpy</span>(tmp, &amp;channel, <span class="keyword">sizeof</span>(channel));</span><br><span class="line">tmp += <span class="keyword">sizeof</span>(channel);</span><br><span class="line"><span class="built_in">memcpy</span>(tmp, img.data, data_size);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">uchar val = tmp[i];</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; (<span class="keyword">int</span>)val &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// copy data to shared memory</span></span><br><span class="line">tmp -= <span class="keyword">sizeof</span>(<span class="keyword">int</span>) * <span class="number">3</span>;</span><br><span class="line"><span class="built_in">memcpy</span>(lp_base, tmp, buffer_size);</span><br><span class="line"></span><br><span class="line"><span class="built_in">free</span>(tmp);</span><br><span class="line"></span><br><span class="line">FlushViewOfFile(lp_base, buffer_size); <span class="comment">// can choose save to file or not</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// process wait here for other task to read data</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"already write to shared memory, wait ..."</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">this_thread::sleep_for(chrono::seconds(<span class="number">6000</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// close shared memory file</span></span><br><span class="line">UnmapViewOfFile(lp_base);</span><br><span class="line">CloseHandle(shared_file_handler);</span><br><span class="line">CloseHandle(hFile);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"shared memory closed"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125; <span class="keyword">else</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"create mapping file error"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span> </span>&#123;</span><br><span class="line"><span class="keyword">char</span>* imgDir = <span class="string">"C:/Users/taoxuan.G08/Documents/Visual Studio 2015/Projects/cnpy-solution/cv/vehicle.jpeg"</span>;</span><br><span class="line">writeMemory(imgDir);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// img_reader.cpp</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;Windows.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2\core\core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2\highgui\highgui.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">readMemory</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">char</span> *shared_object_name = <span class="string">"Local\\object_name_sean"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// open shared memory file</span></span><br><span class="line">HANDLE shared_file_handler = OpenFileMapping(</span><br><span class="line">FILE_MAP_ALL_ACCESS,</span><br><span class="line"><span class="literal">NULL</span>,</span><br><span class="line">shared_object_name);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (shared_file_handler) &#123;</span><br><span class="line"></span><br><span class="line">LPVOID lp_base = MapViewOfFile(</span><br><span class="line">shared_file_handler,</span><br><span class="line">FILE_MAP_ALL_ACCESS,</span><br><span class="line"><span class="number">0</span>,</span><br><span class="line"><span class="number">0</span>,</span><br><span class="line"><span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// copy shared data from memory</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"read shared data: "</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">uchar* tmp = (uchar*)lp_base;</span><br><span class="line"><span class="keyword">int</span> width;</span><br><span class="line"><span class="keyword">int</span> height;</span><br><span class="line"><span class="keyword">int</span> channel;</span><br><span class="line"><span class="built_in">memcpy</span>(&amp;width, tmp, <span class="keyword">sizeof</span>(width));</span><br><span class="line">tmp += <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"><span class="built_in">memcpy</span>(&amp;height, tmp, <span class="keyword">sizeof</span>(height));</span><br><span class="line">tmp += <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"><span class="built_in">memcpy</span>(&amp;channel, tmp, <span class="keyword">sizeof</span>(channel));</span><br><span class="line">tmp += <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"></span><br><span class="line">Mat img = Mat(height, width, CV_8UC3);</span><br><span class="line"><span class="built_in">memcpy</span>(img.data, tmp, height * width * channel);</span><br><span class="line"></span><br><span class="line">namedWindow(<span class="string">"test"</span>);</span><br><span class="line">imshow(<span class="string">"test"</span>, img);</span><br><span class="line">waitKey(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// close share memory file</span></span><br><span class="line">UnmapViewOfFile(lp_base);</span><br><span class="line">CloseHandle(shared_file_handler);</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"open mapping file error"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span> </span>&#123;</span><br><span class="line">readMemory();</span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># img_reader.py</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> ctypes <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">FILE_MAP_ALL_ACCESS = <span class="number">0xF001F</span></span><br><span class="line">szName = c_char_p(<span class="string">'Local\object_name_sean'</span>)</span><br><span class="line"></span><br><span class="line">hMapObject = windll.kernel32.OpenFileMappingA(FILE_MAP_ALL_ACCESS, <span class="keyword">False</span>, szName)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Error after OpenFileMappingA -&gt;"</span>, GetLastError()  <span class="comment"># If everything runs smoothly, GetLastError should return 0</span></span><br><span class="line"><span class="keyword">if</span> hMapObject == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'Could not open file mapping object'</span></span><br><span class="line">    <span class="keyword">raise</span> windll.WindowsError()</span><br><span class="line"></span><br><span class="line">pBuf = windll.kernel32.MapViewOfFile(hMapObject, FILE_MAP_ALL_ACCESS, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Error after MapViewOfFile -&gt;"</span>, GetLastError()  <span class="comment"># If everything runs smoothly, GetLastError should return 0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> pBuf == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'Could not map view of file'</span></span><br><span class="line">    windll.kernel32.GetLastError()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    pBuf_int = cast(pBuf, POINTER(c_int))</span><br><span class="line">    width, height, channel = pBuf_int[:<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    data_len = width * height * channel</span><br><span class="line">    pBuf_ubyte = cast(pBuf, POINTER(c_ubyte))</span><br><span class="line">    data_ubyte = pBuf_ubyte[: data_len]  <span class="comment"># The pointer is already incremented by 12 bytes, not sure why.</span></span><br><span class="line"></span><br><span class="line">    image = np.asarray(data_ubyte, dtype=np.uint8)</span><br><span class="line">    image = image.reshape((height, width, channel))</span><br><span class="line"></span><br><span class="line">    cv2.imshow(<span class="string">'python image'</span>, image)</span><br><span class="line">    cv2.waitKey()</span><br><span class="line"></span><br><span class="line">windll.kernel32.UnmapViewOfFile(pBuf)</span><br><span class="line">windll.kernel32.CloseHandle(hMapObject)</span><br></pre></td></tr></table></figure><p><a href="img_writer.cpp">img_writer in C++</a> <a href="img_reader.cpp">img_reader in C++</a> <a href="img_reader.py">img_reader in python</a></p><p><em><font color="orange">不知为什么，python 版的 reader 用脚本执行正常，但是用 pyinstaller 打包成 exe 后就无法获取共享内存的指针，<code>MapViewOfFile</code> 始终返回 0，正在解决这个问题。</font></em></p><p><em><font color="green">除此之外，发现 python 版中在执行完 <code>OpenFileMappingA</code> 和 <code>MapViewOfFile</code> 后，分别调用 <code>GetLastError</code> 都应该返回 0 (0 表示没有错误)。C++ 版本的 reader 就是如此。但是 <code>img_reader.py</code> 用脚本方式执行却都返回 2，按理说返回 2 了就表示有错，应该无法正确读取共享内存数据，但是用脚本方式执行却可以读取图像数据。这一点很奇怪。而将 <code>img_reader.py</code> 转换成 exe 后，在 <code>OpenFileMappingA</code> 后调用 <code>GetLastError</code> 返回 2，<code>MapViewOfFile</code> 后返回 6，也无法正确读取图像数据。</font></em></p><p>由于现有的方法无法在转成 exe 后成功运行，考虑使用新的方法来读取共享内存。这里使用了 <code>mmap</code> 库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mmap</span><br><span class="line"><span class="keyword">import</span> struct</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">shm = mmap.mmap(<span class="number">0</span>, <span class="number">720</span>*<span class="number">480</span>*<span class="number">3</span>+<span class="number">12</span>, <span class="string">"object_name_sean"</span>, mmap.ACCESS_READ)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> shm</span><br><span class="line"><span class="keyword">if</span> shm:</span><br><span class="line">    header = shm.read(<span class="number">12</span>)</span><br><span class="line">    width_str = header[:<span class="number">4</span>]</span><br><span class="line">    height_str = header[<span class="number">4</span>:<span class="number">8</span>]</span><br><span class="line">    channel_str = header[<span class="number">8</span>:<span class="number">12</span>]</span><br><span class="line"></span><br><span class="line">    width = struct.unpack(<span class="string">'&lt;i'</span>, width_str)[<span class="number">0</span>]</span><br><span class="line">    height = struct.unpack(<span class="string">'&lt;i'</span>, height_str)[<span class="number">0</span>]</span><br><span class="line">    channel = struct.unpack(<span class="string">'&lt;i'</span>, channel_str)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> width, height, channel</span><br><span class="line"></span><br><span class="line">    data = shm.read(width * height * channel)</span><br><span class="line"></span><br><span class="line">    img_data = [ord(x) <span class="keyword">for</span> x <span class="keyword">in</span> data]</span><br><span class="line">    <span class="keyword">print</span> img_data[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line">    image = np.asarray(img_data, dtype=np.uint8)</span><br><span class="line">    image = image.reshape((height, width, channel))</span><br><span class="line"></span><br><span class="line">    cv2.imshow(<span class="string">'python image'</span>, image)</span><br><span class="line">    cv2.waitKey()</span><br><span class="line"></span><br><span class="line">shm.close()</span><br></pre></td></tr></table></figure><p><a href="reader_mmap.py">img reader in python mmap</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记载了在 Windows 下如何通过调用 WinApi ，利用 &lt;code&gt;共享内存&lt;/code&gt; 实现 进程间通信 (Inter Process Communication, IPC).&lt;/p&gt;
    
    </summary>
    
    
      <category term="C++" scheme="https://taosean.github.io/tags/C/"/>
    
      <category term="Windows" scheme="https://taosean.github.io/tags/Windows/"/>
    
      <category term="IPC" scheme="https://taosean.github.io/tags/IPC/"/>
    
      <category term="Python" scheme="https://taosean.github.io/tags/Python/"/>
    
      <category term="WinAPI" scheme="https://taosean.github.io/tags/WinAPI/"/>
    
      <category term="file mapping" scheme="https://taosean.github.io/tags/file-mapping/"/>
    
      <category term="进程通信" scheme="https://taosean.github.io/tags/%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1/"/>
    
  </entry>
  
  <entry>
    <title>Visual Studio 环境变量配置</title>
    <link href="https://taosean.github.io/2018/11/26/Visual-Studio-Configuration/"/>
    <id>https://taosean.github.io/2018/11/26/Visual-Studio-Configuration/</id>
    <published>2018-11-26T03:18:03.000Z</published>
    <updated>2019-05-31T06:58:15.289Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记录了一些关于 Visual Studio 的环境变量的配置，本文使用的版本是 VS 2015.</p><a id="more"></a><h2 id="vs-的项目结构"><a class="markdownIt-Anchor" href="#vs-的项目结构"></a> VS 的项目结构</h2><p>  Visual Studio 主要由两层结构，最大的一层是 <code>解决方案 (Solution)</code>，一个 <code>解决方案</code> 可以包含多个 <code>项目 (Project)</code>。可以在一个已有的 <code>Solution</code> 里添加 <code>Project</code>.</p><br>## VS 平台选项&emsp;&emsp;VS 由 `Debug` 和 `Release` 两种模式，一般在开发阶段都使用 Debug，而在最后的发布阶段使用 Release。在目标平台选项主要有 `x64` 和 `x86` 两种。模式和平台相互组合就会产生 4 种方式。可根据需要进行环境变量的配置。<br>## 项目属性配置&emsp;&emsp;在某个项目上(是项目，非解决方案)`右键`，`属性`，选中左侧 `VC++目录`，右侧会出现一些路径的配置。主要有 `可执行文件目录`，`包含目录`，`引用目录`，`库目录`等等。在安装 VS 的时候，VS 已经将一些依赖的目录命名到一些宏了（就是类似于系统的环境变量之类的变量，与 C++ 的宏不一样），因此上面这些 `可执行文件目录` 等都包含了一些宏，作为默认的查找路径，如果自己的项目需要额外引入其他的依赖，则需要在对应的目录里添加自己的路径。比如，C++ 中调用 Python 的项目需要 `Python.h` 和 `python27.lib`，因此就将这两个文件所在的路径分别添加进 `包含目录` 和 `库目录`。上面的每一个目录都是和环境变量的某个变量对应的。比如，`包含目录` 与 环境变量 `INCLUDE` 对应，`库目录` 与 环境变量 `LIB` 对应。**Note:** 当选用 `Debug` 模式时，编译的时候会报找不到 `python27_d.lib` 的错，这是因为我们下载的 python 都是 Release 版本的。因此只有 `python27.lib` 没有 `python27_d.lib`。[解决方法](https://blog.csdn.net/Chris_zhangrx/article/details/78947526)<br>## 包含目录、附加包含目录以及库目录和附加库目录的区别在 VS 中，右键一个 Project，可以发现有两个地方设置 `Include` 的相关目录：<blockquote><p>VC++ Directories -&gt; Include Directories<br>C/C++ -&gt; General -&gt; Additional Include Directories</p></blockquote><p>同理，设置 Lib 也有两个地方</p><blockquote><p>VC++ Directories -&gt; LibraryDirectories<br>Linker -&gt; General -&gt; Additional Library Directories</p></blockquote><p>应该如何设置呢？<br>MSDN 对这两个条目的解释如下</p><blockquote><p>“VC++ Directories -&gt; Include Directories” : Directory settings displayed in the window are the directories that Visual Studio will search for include files referred to in your source code files. Corresponds to environment variable INCLUDE.<br>“C/C+±&gt; General -&gt; Additional Include Directories”: The directory to be added to the list of directories searched for include files.</p></blockquote><p>编译器在编译过程中查找包含目录（<strong>Include</strong> 文件）的顺序：</p><blockquote><p>The compiler searches for directories in the following order:<br>1. Directories containing the source file.<br>2. Directories specified with the <strong>/I</strong> option, in the order that CL encounters them.<br>3. Directories specified in the <strong>INCLUDE</strong> environment variable.</p></blockquote><p>其中 step2 中的 <code>/I</code> 是由 <code>C/C++ -&gt; General -&gt; Additional Include Directories</code> 设置的。<br>而 step3 中的 <code>INCLUDE</code> 是由 <code>VC++ Directories -&gt; Include Directories</code> 设置的。<br>所以从这里看出，不同的设置有不同的编译链接顺序。</p><p>因此，总结出两种设置方法：</p><blockquote><p>VC++ Directories -&gt; Include Directories 配合 VC++ Directories -&gt; LibraryDirectories<br>C/C++ -&gt; General -&gt; Additional Include Directories 配合 Linker -&gt; General -&gt; Additional Library Directories</p></blockquote><p>但是要注意，由于编译顺序，这种用法情况下需要确保在 <code>VC++ Directories -&gt; Include Directories</code> 中填入 <code>$(IncludePath)</code> (继承其他 Include 路径).</p><p>Lib 的设置与 Include 同理。</p><br>## 参考文章[visual studio配置中包含目录和附加包含目录的区别以及auto-linking](https://blog.csdn.net/u012234115/article/details/54233095)[VS属性配置和auto-linking](https://blog.csdn.net/zcedar/article/details/51444343)]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记录了一些关于 Visual Studio 的环境变量的配置，本文使用的版本是 VS 2015.&lt;/p&gt;
    
    </summary>
    
    
      <category term="C++" scheme="https://taosean.github.io/tags/C/"/>
    
      <category term="visual studio" scheme="https://taosean.github.io/tags/visual-studio/"/>
    
      <category term="环境变量" scheme="https://taosean.github.io/tags/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"/>
    
      <category term="Debug" scheme="https://taosean.github.io/tags/Debug/"/>
    
      <category term="Release" scheme="https://taosean.github.io/tags/Release/"/>
    
      <category term="调试" scheme="https://taosean.github.io/tags/%E8%B0%83%E8%AF%95/"/>
    
      <category term="发行" scheme="https://taosean.github.io/tags/%E5%8F%91%E8%A1%8C/"/>
    
  </entry>
  
  <entry>
    <title>相机成像原理和参数标定</title>
    <link href="https://taosean.github.io/2018/11/15/camera-calibration/"/>
    <id>https://taosean.github.io/2018/11/15/camera-calibration/</id>
    <published>2018-11-15T06:38:10.000Z</published>
    <updated>2018-11-16T03:10:41.845Z</updated>
    
    <content type="html"><![CDATA[<p>最近学习了相机的成像原理和参数标定，将参考文献记录如下。</p><a id="more"></a><h2 id="成像原理"><a class="markdownIt-Anchor" href="#成像原理"></a> 成像原理</h2><p>简化后的相机模型和针孔相机的成像原理很相似，因此我们把简化后的相机模型称为针孔相机模型。<br>具体内容参考<a href="https://zhuanlan.zhihu.com/p/30813733" target="_blank" rel="noopener">相机成像过程的简化与建模</a><br><br></p><h2 id="世界坐标到相机坐标变换"><a class="markdownIt-Anchor" href="#世界坐标到相机坐标变换"></a> 世界坐标到相机坐标变换</h2><p><a href="https://zhuanlan.zhihu.com/p/23090593" target="_blank" rel="noopener">刚体变换</a><br><a href="https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula" target="_blank" rel="noopener">罗德里格斯旋转公式</a><br><a href="https://www.matongxue.com/madocs/244.html" target="_blank" rel="noopener">仿射变换</a></p><h2 id="相机坐标到数字图像坐标畸变矫正"><a class="markdownIt-Anchor" href="#相机坐标到数字图像坐标畸变矫正"></a> 相机坐标到数字图像坐标，畸变矫正</h2><p><a href="https://zhuanlan.zhihu.com/p/30813733" target="_blank" rel="noopener">相机标定究竟在标定什么？</a></p><h2 id="心得"><a class="markdownIt-Anchor" href="#心得"></a> 心得</h2><ol><li>由于针孔相机模型的特性（射线），CCD 上的某个点可能对应了一个射线上的所有点，因此无法只通过相机内参将像素坐标 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(u,v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span> 映射为相机坐标 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>c</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>c</mi></msub><mo separator="true">,</mo><msub><mi>z</mi><mi>c</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_c, y_c, z_c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。因而无法计算出两个像素点之间的实际物理距离。（远处的大物体移动大距离和近处的小物体移动小距离可能成像结果完全一样）</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近学习了相机的成像原理和参数标定，将参考文献记录如下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="camera" scheme="https://taosean.github.io/tags/camera/"/>
    
      <category term="calibration" scheme="https://taosean.github.io/tags/calibration/"/>
    
      <category term="imaging" scheme="https://taosean.github.io/tags/imaging/"/>
    
      <category term="相机" scheme="https://taosean.github.io/tags/%E7%9B%B8%E6%9C%BA/"/>
    
      <category term="成像原理" scheme="https://taosean.github.io/tags/%E6%88%90%E5%83%8F%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow-1.x-cookbook 读书笔记</title>
    <link href="https://taosean.github.io/2018/11/14/tensorflow-1-x-cookbook/"/>
    <id>https://taosean.github.io/2018/11/14/tensorflow-1-x-cookbook/</id>
    <published>2018-11-14T02:02:04.000Z</published>
    <updated>2018-11-14T05:29:08.835Z</updated>
    
    <content type="html"><![CDATA[<p>本文是关于 《TensorFlow 1.x Deep Learning Cookbook》 的读书笔记。</p><a id="more"></a><br>## Hello world in TensorFlow1. 设置 tensorflow 输出日志等级<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'TF_CPP_MIN_LOG_LEVEL'</span>]=<span class="string">'2'</span></span><br></pre></td></tr></table></figure><ol start="2"><li>TensorFlow 与设备</li></ol><blockquote><p>TensorFlow allows you to use specific devices (CPU/GPU) with different objects of the computation graph using with <code>tf.device()</code>.</p></blockquote><h2 id="working-with-constants-variables-and-placeholders"><a class="markdownIt-Anchor" href="#working-with-constants-variables-and-placeholders"></a> Working with constants, variables, and placeholders</h2><ol start="3"><li>Constants 和 Variables 的存储方式</li></ol><blockquote><p>Constants are stored in the computation graph definition; they are loaded every time the graph is loaded. In other words, they are memory expensive. Variables, on the other hand, are stored separately; they can exist on the parameter server.</p></blockquote><ol start="4"><li>设置全局 seed</li></ol><blockquote><p>When there are large numbers of random tensors in use, we can set the seed for all randomly generated tensors using tf.set_random_seed(); the following command sets the seed for random tensors for all sessions as 54: <code>tf.set_random_seed(54)</code></p></blockquote><ol start="5"><li>以某种分布初始化 Variable</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rand_t = tf.random_uniform([<span class="number">50</span>,<span class="number">50</span>], <span class="number">0</span>, <span class="number">10</span>, seed=<span class="number">0</span>)</span><br><span class="line">t_a = tf.Variable(rand_t)</span><br><span class="line">t_b = tf.Variable(rand_t)</span><br></pre></td></tr></table></figure><ol start="6"><li>将 Variable 作常量使用以优化内存 (Constant 存储在 graph 中，Variable 不是)</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t_large = tf.Variable(large_array, trainable = <span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><h2 id="performing-matrix-manipulations-using-tensorflow"><a class="markdownIt-Anchor" href="#performing-matrix-manipulations-using-tensorflow"></a> Performing matrix manipulations using TensorFlow</h2><ol start="7"><li>elementwise operations</li></ol><blockquote><p>All arithmetic operations of matrices like add, sub, div, multiply (elementwise multiplication), mod, and cross require that the two tensor matrices should be of the same data type.</p></blockquote><h2 id="invoking-cpugpu-devices"><a class="markdownIt-Anchor" href="#invoking-cpugpu-devices"></a> Invoking CPU/GPU devices</h2><ol start="8"><li>TensorFlow naming CPU and GPU devices</li></ol><blockquote><p>TensorFlow names the supported devices as “<code>/device:CPU:0</code>” (or “<code>/cpu:0</code>”) for the CPU devices and “<code>/device:GPU:I</code>” (or “<code>/gpu:I</code>”) for the ith GPU device.</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是关于 《TensorFlow 1.x Deep Learning Cookbook》 的读书笔记。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ORB 特征提取</title>
    <link href="https://taosean.github.io/2018/11/13/ORB-Feature/"/>
    <id>https://taosean.github.io/2018/11/13/ORB-Feature/</id>
    <published>2018-11-13T03:15:01.000Z</published>
    <updated>2018-11-13T06:31:52.026Z</updated>
    
    <content type="html"><![CDATA[<p>ORB 特征的提取过程</p><a id="more"></a><p>以下两篇博客讲解得不错，结合起来看更易理解。<br><a href="https://blog.csdn.net/zouzoupaopao229/article/details/52625678" target="_blank" rel="noopener">ORB特征提取详解</a><br><a href="https://blog.csdn.net/yang843061497/article/details/38553765" target="_blank" rel="noopener">见过的介绍ORB最清楚的博文</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ORB 特征的提取过程&lt;/p&gt;
    
    </summary>
    
    
      <category term="特征提取" scheme="https://taosean.github.io/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"/>
    
      <category term="图像检索" scheme="https://taosean.github.io/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
      <category term="图像匹配" scheme="https://taosean.github.io/tags/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/"/>
    
      <category term="feature extraction" scheme="https://taosean.github.io/tags/feature-extraction/"/>
    
      <category term="ORB" scheme="https://taosean.github.io/tags/ORB/"/>
    
      <category term="keypoint" scheme="https://taosean.github.io/tags/keypoint/"/>
    
  </entry>
  
  <entry>
    <title>Faster RCNN 中自定义 Python 层的作用理解</title>
    <link href="https://taosean.github.io/2018/11/06/Faster-RCNN-Python-layer/"/>
    <id>https://taosean.github.io/2018/11/06/Faster-RCNN-Python-layer/</id>
    <published>2018-11-06T07:08:17.000Z</published>
    <updated>2018-11-19T10:46:53.478Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要分析了 Faster RCNN 中 <code>anchor_target_layer.py</code>, <code>proposal_target_layer.py</code> 和 <code>proposal_layer.py</code> 三个自定义 python 层的代码。</p><a id="more"></a><h2 id="训练阶段的主要网络结构"><a class="markdownIt-Anchor" href="#训练阶段的主要网络结构"></a> 训练阶段的主要网络结构</h2><p><img src="structure.PNG" alt="训练阶段的主要网络结构"></p><h2 id="测试阶段的主要网络结构"><a class="markdownIt-Anchor" href="#测试阶段的主要网络结构"></a> 测试阶段的主要网络结构</h2><p><img src="structure_test.PNG" alt="测试阶段的主要网络结构"></p><br>## proposal_layer.py （训练，测试阶段都有）[source](https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/rpn/proposal_layer.py)输入： score, bbox_deltas, im_info1. 生成 anchors, 利用预测得到的 bbox_deltas 作为输入，对所有的 anchors 作回归，得到 proposals. (注意，这里生成 anchors 的方式与训练时 anchor_target_layer.py 里一致)2. 对超出原图的 proposals 进行 clip, 筛除尺寸过小的 proposals.3. 根据输入的 scores 进行排序，选取前 N 个保留。（eg. 6000）4. 对剩下的 proposals 进行 nms，筛除一部分 proposals.5. 再根据 scores 排序，选取前一部分 proposals. (eg. 300)6. 输出 proposals<br>## anchor_target_layer.py (仅在训练阶段)[source](https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/rpn/anchor_target_layer.py)输入: 'rpn_cls_score','gt_boxes','im_info', 'data'(1) 生成 所有的 anchors，记为 `all_anchors`，选出在图像内部的 anchor，记为 `anchors`.(2) 生成与 1 步中 `anchors` 同尺寸的 `labels`，初始化为 `-1`.(3) 计算 `anchors` 与 `gt_boxes` 的 IoU，得到 `overlaps`，得到每个 anchor 对应的 gt_box (IoU 最大).(4) 根据 RPN 正负样本选取规则 1，将每个 gt_box 的 IoU 最大 anchor 的 label 置为 `1`.(5) 根据 RPN 正负样本选取规则 2，将与任意 gt_box 的 IoU 大于某阈值的 anchor 的 label 置为 `1`. 将与所有 gt_box 的 IoU 小于某阈值的 achor 的 label 置为 `0`. 剩下的保留为 `-1`. 这样，就为每个 anchor 分配了标签。(6) 根据正负样本的数量限制，将一部分正样本（label 为 1）置为 `-1`. 负样本同样。(7) 计算 `anchors` 中每个 anchor 和 其对应的 gt_box 之间的 delta 作为 `bbox_targets`.   这样，上面计算得到的 `labels` 和 `bbox_targets` 其实就是 RPN 网络的 loss 的真值。(8) 将得到的 `anchors` 和 `bbox_targets` unmap 回原来的 `all_anchors` 中。这样，所有生成的 anchors 都有一个类别标记（-1，0，1）和 bbox_targets. (在 `all_anchors` 不在 `anchors` 中的 anchor 的 bbox_target 用 0 填充。label 用 -1 填充。这样在计算 RPN loss 时不会计算此 anchor 的 loss.(-1 被忽略))。(9) 将 `all_anchors` 的 `labels` 和 `bbox_targets` 输出，与预测的结果计算 rpn_loss.<br>## proposal_target_layer.py (仅在训练阶段) [source](https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/rpn/proposal_target_layer.py)接受 proposal_layer.py 的输出 和 gt_boxes (每个 GT box 的坐标和类别)作为输入，格式 (0, x1, y1, x2, y2)1. 将输入的 rois 和 gt_boxes 合并 (vstack)，形成总的 rois, 共 M 个。2. 计算每个 roi 和每个 gt_box 的 IoU，形成一个 matrix，设 gt_boxes 共有 N 个，则尺寸为 $M\times N$.3. 找到每个 roi 对应的 IoU 最大的 gt_box 的索引，并将此 gt_box 的类别赋给此 roi. 这样每个 roi 都有一个物体类别。4. 选择一些 IoU 大于某阈值的 roi 作为 foreground，选择一些 IoU 在某区间内的 roi 作为 background。将作为 background 的 roi 的类别改为 0，用作最后 loss_cls 的计算。将 fg rois 和 bg rois 合并(vstack)，作为一个输出。记为 rois，用作 ROI Pooling.5. 计算这些 rois (第四部获得)于其对应的 gt_boxes 之间的 delta 作为位置预测的目标，用来计算 loss_bbox.]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要分析了 Faster RCNN 中 &lt;code&gt;anchor_target_layer.py&lt;/code&gt;, &lt;code&gt;proposal_target_layer.py&lt;/code&gt; 和 &lt;code&gt;proposal_layer.py&lt;/code&gt; 三个自定义 python 层的代码。&lt;/p&gt;
    
    </summary>
    
    
      <category term="目标检测" scheme="https://taosean.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Faster R-CNN" scheme="https://taosean.github.io/tags/Faster-R-CNN/"/>
    
      <category term="RPN" scheme="https://taosean.github.io/tags/RPN/"/>
    
      <category term="anchor" scheme="https://taosean.github.io/tags/anchor/"/>
    
      <category term="Python layer" scheme="https://taosean.github.io/tags/Python-layer/"/>
    
  </entry>
  
</feed>
